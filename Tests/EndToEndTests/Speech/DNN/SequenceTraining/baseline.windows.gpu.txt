CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 6
    Total Memory: 58719796 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk currentDirectory=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData RunDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu DataDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining OutputDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.3.1+ (HEAD 35ac14, Jan  9 2018 23:34:09) at 2018/01/10 00:17:03

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk  currentDirectory=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData  RunDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu  DataDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining  OutputDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData
-------------------------------------------------------------------
Build info: 

		Built time: Jan  9 2018 23:21:17
		Last modified date: Tue Jan  9 03:03:40 2018
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		With ASGD: yes
		Math lib: mkl
		CUDA version: 9.0.0
		CUDNN version: 6.0.21
		Build Branch: HEAD
		Build SHA1: 35ac148b61d84c185805e9829cee98f267e8a3f0
		MPI distribution: Microsoft MPI
		MPI version: 7.0.12437.6
-------------------------------------------------------------------
-------------------------------------------------------------------
GPU info:

		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8124 MB; free memory = 8001 MB
-------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:DataDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
        labelMappingFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        useMersenneTwisterRand=true      
        frameMode = false
        nbruttsineachrecurrentiter = 1
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
            labelMappingFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying"
            transpFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
01/10/2018 00:17:04: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
01/10/2018 00:17:04: precision = "float"

01/10/2018 00:17:04: ##############################################################################
01/10/2018 00:17:04: #                                                                            #
01/10/2018 00:17:04: # dptPre1 command (train action)                                             #
01/10/2018 00:17:04: #                                                                            #
01/10/2018 00:17:04: ##############################################################################

01/10/2018 00:17:04: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/10/2018 00:17:04: 
Model has 19 nodes. Using GPU 0.

01/10/2018 00:17:04: Training criterion:   ce = CrossEntropyWithSoftmax
01/10/2018 00:17:04: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 2 are aliased.
	OL.t (gradient) reuses OL.z (gradient)

Memory Sharing: Out of 29 matrices, 11 are shared as 3, and 18 are not shared.

Here are the ones that share memory:
	{ HL1.W : [512 x 363] (gradient)
	  HL1.t : [512 x *]
	  HL1.y : [512 x 1 x *] }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *]
	  OL.t : [132 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  HL1.z : [512 x 1 x *]
	  OL.z : [132 x 1 x *] }

Here are the ones that don't share memory:
	{scaledLogLikelihood : [132 x 1 x *]}
	{features : [363 x *]}
	{globalInvStd : [363 x 1]}
	{globalMean : [363 x 1]}
	{globalPrior : [132 x 1]}
	{labels : [132 x *]}
	{OL.b : [132 x 1]}
	{HL1.W : [512 x 363]}
	{OL.W : [132 x 512]}
	{HL1.b : [512 x 1]}
	{featNorm : [363 x *]}
	{logPrior : [132 x 1]}
	{ce : [1] (gradient)}
	{ce : [1]}
	{OL.W : [132 x 512] (gradient)}
	{HL1.b : [512 x 1] (gradient)}
	{OL.b : [132 x 1] (gradient)}
	{err : [1]}


01/10/2018 00:17:04: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

01/10/2018 00:17:04: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 00:17:04: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:04: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 00:17:04: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 00:17:04: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/10/2018 00:17:04: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 00:17:04: Starting minibatch loop.
01/10/2018 00:17:04:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.89978218 * 2560; err = 0.84375000 * 2560; time = 0.2294s; samplesPerSecond = 11161.2
01/10/2018 00:17:04:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.96755714 * 2560; err = 0.72031250 * 2560; time = 0.0100s; samplesPerSecond = 255343.8
01/10/2018 00:17:04:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.55723495 * 2560; err = 0.65859375 * 2560; time = 0.0092s; samplesPerSecond = 279055.6
01/10/2018 00:17:04:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.29642792 * 2560; err = 0.61992187 * 2560; time = 0.0090s; samplesPerSecond = 284258.1
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 2.02396393 * 2560; err = 0.55117187 * 2560; time = 0.0090s; samplesPerSecond = 284090.9
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87309265 * 2560; err = 0.51484375 * 2560; time = 0.0089s; samplesPerSecond = 286433.6
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.78157196 * 2560; err = 0.50507813 * 2560; time = 0.0091s; samplesPerSecond = 282056.4
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.75391235 * 2560; err = 0.50781250 * 2560; time = 0.0091s; samplesPerSecond = 280176.4
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66460266 * 2560; err = 0.45742187 * 2560; time = 0.0100s; samplesPerSecond = 256821.8
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62184296 * 2560; err = 0.47968750 * 2560; time = 0.0131s; samplesPerSecond = 195147.2
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.65328217 * 2560; err = 0.47265625 * 2560; time = 0.0131s; samplesPerSecond = 194839.8
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.50686951 * 2560; err = 0.44921875 * 2560; time = 0.0088s; samplesPerSecond = 290354.8
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.46723938 * 2560; err = 0.42304687 * 2560; time = 0.0091s; samplesPerSecond = 282308.3
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.49163513 * 2560; err = 0.44140625 * 2560; time = 0.0088s; samplesPerSecond = 291127.4
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46437683 * 2560; err = 0.43398437 * 2560; time = 0.0088s; samplesPerSecond = 291256.6
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43047791 * 2560; err = 0.43867187 * 2560; time = 0.0091s; samplesPerSecond = 282404.9
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.42104797 * 2560; err = 0.41992188 * 2560; time = 0.0088s; samplesPerSecond = 291352.7
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.46536865 * 2560; err = 0.42421875 * 2560; time = 0.0089s; samplesPerSecond = 287137.2
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.47427673 * 2560; err = 0.44062500 * 2560; time = 0.0088s; samplesPerSecond = 292274.1
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42848816 * 2560; err = 0.44062500 * 2560; time = 0.0088s; samplesPerSecond = 291724.6
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.34078674 * 2560; err = 0.41171875 * 2560; time = 0.0087s; samplesPerSecond = 292795.6
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.39474792 * 2560; err = 0.42773438 * 2560; time = 0.0089s; samplesPerSecond = 287156.5
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.40156250 * 2560; err = 0.41250000 * 2560; time = 0.0088s; samplesPerSecond = 292144.1
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.39350281 * 2560; err = 0.42734375 * 2560; time = 0.0088s; samplesPerSecond = 292180.7
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.32500916 * 2560; err = 0.40156250 * 2560; time = 0.0091s; samplesPerSecond = 280637.1
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.27034607 * 2560; err = 0.39804688 * 2560; time = 0.0088s; samplesPerSecond = 290193.5
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.32393494 * 2560; err = 0.39375000 * 2560; time = 0.0105s; samplesPerSecond = 244613.3
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25440979 * 2560; err = 0.38437500 * 2560; time = 0.0138s; samplesPerSecond = 185072.7
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.23372498 * 2560; err = 0.37148437 * 2560; time = 0.0135s; samplesPerSecond = 190196.0
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20885620 * 2560; err = 0.35976562 * 2560; time = 0.0125s; samplesPerSecond = 205539.9
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23717957 * 2560; err = 0.36953125 * 2560; time = 0.0139s; samplesPerSecond = 184694.9
01/10/2018 00:17:05:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.23036499 * 2560; err = 0.37382813 * 2560; time = 0.0114s; samplesPerSecond = 224433.4
01/10/2018 00:17:05: Finished Epoch[ 1 of 2]: [Training] ce = 1.65179615 * 81920; err = 0.46795654 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.666767s
01/10/2018 00:17:05: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

01/10/2018 00:17:05: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:05: Starting minibatch loop.
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.21826115 * 2560; err = 0.37031250 * 2560; time = 0.0108s; samplesPerSecond = 236349.9
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18394566 * 2560; err = 0.36640625 * 2560; time = 0.0087s; samplesPerSecond = 294958.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.17353325 * 2560; err = 0.35976562 * 2560; time = 0.0087s; samplesPerSecond = 292768.8
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.20286140 * 2560; err = 0.35859375 * 2560; time = 0.0085s; samplesPerSecond = 302937.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19606552 * 2560; err = 0.37812500 * 2560; time = 0.0085s; samplesPerSecond = 300145.4
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.16461678 * 2560; err = 0.34375000 * 2560; time = 0.0137s; samplesPerSecond = 187431.8
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.13763046 * 2560; err = 0.34765625 * 2560; time = 0.0108s; samplesPerSecond = 237032.6
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.19578094 * 2560; err = 0.37226562 * 2560; time = 0.0145s; samplesPerSecond = 176638.2
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.24385757 * 2560; err = 0.38046875 * 2560; time = 0.0150s; samplesPerSecond = 170548.4
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18975372 * 2560; err = 0.36093750 * 2560; time = 0.0134s; samplesPerSecond = 190620.9
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.16871338 * 2560; err = 0.35625000 * 2560; time = 0.0144s; samplesPerSecond = 177555.8
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.24394531 * 2560; err = 0.37929687 * 2560; time = 0.0126s; samplesPerSecond = 202461.2
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.18284454 * 2560; err = 0.34921875 * 2560; time = 0.0090s; samplesPerSecond = 285583.6
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.21535187 * 2560; err = 0.36875000 * 2560; time = 0.0087s; samplesPerSecond = 293369.4
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.19859619 * 2560; err = 0.37187500 * 2560; time = 0.0086s; samplesPerSecond = 297910.0
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.14699402 * 2560; err = 0.34648438 * 2560; time = 0.0084s; samplesPerSecond = 303371.5
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.14664307 * 2560; err = 0.35859375 * 2560; time = 0.0087s; samplesPerSecond = 293564.5
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.17961731 * 2560; err = 0.35234375 * 2560; time = 0.0083s; samplesPerSecond = 309702.4
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14800873 * 2560; err = 0.35234375 * 2560; time = 0.0086s; samplesPerSecond = 296509.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08513489 * 2560; err = 0.33320312 * 2560; time = 0.0082s; samplesPerSecond = 311091.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.14455261 * 2560; err = 0.34726563 * 2560; time = 0.0082s; samplesPerSecond = 312763.4
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.16282043 * 2560; err = 0.35703125 * 2560; time = 0.0085s; samplesPerSecond = 299857.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.19267578 * 2560; err = 0.37265625 * 2560; time = 0.0087s; samplesPerSecond = 294584.7
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.15575562 * 2560; err = 0.34882812 * 2560; time = 0.0147s; samplesPerSecond = 173769.0
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.15968018 * 2560; err = 0.35351563 * 2560; time = 0.0140s; samplesPerSecond = 183086.0
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08686829 * 2560; err = 0.33007813 * 2560; time = 0.0131s; samplesPerSecond = 195071.4
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10071411 * 2560; err = 0.34804687 * 2560; time = 0.0127s; samplesPerSecond = 201763.9
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.06582336 * 2560; err = 0.33945313 * 2560; time = 0.0146s; samplesPerSecond = 175166.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09620972 * 2560; err = 0.33085938 * 2560; time = 0.0082s; samplesPerSecond = 310495.0
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.15163269 * 2560; err = 0.35195312 * 2560; time = 0.0085s; samplesPerSecond = 299579.9
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.10898132 * 2560; err = 0.34296875 * 2560; time = 0.0082s; samplesPerSecond = 312275.1
01/10/2018 00:17:05:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06808777 * 2560; err = 0.32304688 * 2560; time = 0.0080s; samplesPerSecond = 318816.4
01/10/2018 00:17:05: Finished Epoch[ 2 of 2]: [Training] ce = 1.15987368 * 81920; err = 0.35476074 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.341085s
01/10/2018 00:17:05: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

01/10/2018 00:17:05: Action "train" complete.


01/10/2018 00:17:05: ##############################################################################
01/10/2018 00:17:05: #                                                                            #
01/10/2018 00:17:05: # addLayer2 command (edit action)                                            #
01/10/2018 00:17:05: #                                                                            #
01/10/2018 00:17:05: ##############################################################################


01/10/2018 00:17:05: Action "edit" complete.


01/10/2018 00:17:05: ##############################################################################
01/10/2018 00:17:05: #                                                                            #
01/10/2018 00:17:05: # dptPre2 command (train action)                                             #
01/10/2018 00:17:05: #                                                                            #
01/10/2018 00:17:05: ##############################################################################

01/10/2018 00:17:05: 
Starting from checkpoint. Loading network from 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/10/2018 00:17:05: 
Model has 24 nodes. Using GPU 0.

01/10/2018 00:17:05: Training criterion:   ce = CrossEntropyWithSoftmax
01/10/2018 00:17:05: Evaluation criterion: err = ClassificationError

01/10/2018 00:17:05: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

01/10/2018 00:17:05: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 00:17:05: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:05: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 00:17:05: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:05: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 00:17:05: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 00:17:05: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/10/2018 00:17:05: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 00:17:06: Starting minibatch loop.
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 4.68514671 * 2560; err = 0.80507812 * 2560; time = 0.0188s; samplesPerSecond = 136003.8
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.83540916 * 2560; err = 0.69765625 * 2560; time = 0.0106s; samplesPerSecond = 242534.5
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.27396317 * 2560; err = 0.59335938 * 2560; time = 0.0106s; samplesPerSecond = 242240.7
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.93453598 * 2560; err = 0.52070313 * 2560; time = 0.0106s; samplesPerSecond = 240447.8
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.72010727 * 2560; err = 0.47890625 * 2560; time = 0.0105s; samplesPerSecond = 243348.3
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.61654205 * 2560; err = 0.47070313 * 2560; time = 0.0105s; samplesPerSecond = 242674.7
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.51410522 * 2560; err = 0.44140625 * 2560; time = 0.0106s; samplesPerSecond = 240864.1
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.49882050 * 2560; err = 0.43671875 * 2560; time = 0.0105s; samplesPerSecond = 243078.0
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.45906067 * 2560; err = 0.41835937 * 2560; time = 0.0106s; samplesPerSecond = 242525.3
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41359100 * 2560; err = 0.40937500 * 2560; time = 0.0105s; samplesPerSecond = 243253.5
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41605682 * 2560; err = 0.41093750 * 2560; time = 0.0112s; samplesPerSecond = 228835.0
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.34621582 * 2560; err = 0.39531250 * 2560; time = 0.0110s; samplesPerSecond = 232149.0
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.32200775 * 2560; err = 0.39257813 * 2560; time = 0.0179s; samplesPerSecond = 142923.3
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33358459 * 2560; err = 0.39609375 * 2560; time = 0.0120s; samplesPerSecond = 214111.3
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32798462 * 2560; err = 0.39023438 * 2560; time = 0.0119s; samplesPerSecond = 215758.8
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28152161 * 2560; err = 0.38906250 * 2560; time = 0.0106s; samplesPerSecond = 241815.1
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.29407654 * 2560; err = 0.38476563 * 2560; time = 0.0108s; samplesPerSecond = 237807.7
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.29927979 * 2560; err = 0.39023438 * 2560; time = 0.0105s; samplesPerSecond = 242773.7
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.33316956 * 2560; err = 0.40546875 * 2560; time = 0.0108s; samplesPerSecond = 237048.0
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32376099 * 2560; err = 0.41406250 * 2560; time = 0.0106s; samplesPerSecond = 242254.5
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.23729553 * 2560; err = 0.37539062 * 2560; time = 0.0112s; samplesPerSecond = 227962.8
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.27207336 * 2560; err = 0.38906250 * 2560; time = 0.0113s; samplesPerSecond = 227038.9
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.26402893 * 2560; err = 0.37695313 * 2560; time = 0.0108s; samplesPerSecond = 237576.0
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.24779053 * 2560; err = 0.36992188 * 2560; time = 0.0106s; samplesPerSecond = 241625.7
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.21864014 * 2560; err = 0.36757812 * 2560; time = 0.0106s; samplesPerSecond = 240782.5
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19121704 * 2560; err = 0.37070313 * 2560; time = 0.0106s; samplesPerSecond = 242447.2
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23925476 * 2560; err = 0.36835937 * 2560; time = 0.0107s; samplesPerSecond = 239552.3
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.18916016 * 2560; err = 0.36406250 * 2560; time = 0.0116s; samplesPerSecond = 221355.6
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.17012329 * 2560; err = 0.35351563 * 2560; time = 0.0116s; samplesPerSecond = 221533.8
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14500122 * 2560; err = 0.33984375 * 2560; time = 0.0106s; samplesPerSecond = 241771.7
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.17140808 * 2560; err = 0.35000000 * 2560; time = 0.0183s; samplesPerSecond = 139850.2
01/10/2018 00:17:06:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.18915710 * 2560; err = 0.36992188 * 2560; time = 0.0117s; samplesPerSecond = 219384.7
01/10/2018 00:17:06: Finished Epoch[ 1 of 2]: [Training] ce = 1.52387781 * 81920; err = 0.42613525 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.49801s
01/10/2018 00:17:06: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

01/10/2018 00:17:06: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:06: Starting minibatch loop.
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.18371334 * 2560; err = 0.35312500 * 2560; time = 0.0130s; samplesPerSecond = 197530.9
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.15387115 * 2560; err = 0.35195312 * 2560; time = 0.0106s; samplesPerSecond = 241552.7
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15634022 * 2560; err = 0.35078125 * 2560; time = 0.0108s; samplesPerSecond = 238088.6
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.13972702 * 2560; err = 0.34531250 * 2560; time = 0.0106s; samplesPerSecond = 242174.3
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.14528008 * 2560; err = 0.36445312 * 2560; time = 0.0106s; samplesPerSecond = 242114.7
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.14011345 * 2560; err = 0.33476563 * 2560; time = 0.0106s; samplesPerSecond = 242174.3
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.09710693 * 2560; err = 0.33671875 * 2560; time = 0.0107s; samplesPerSecond = 238643.5
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.15687256 * 2560; err = 0.35546875 * 2560; time = 0.0106s; samplesPerSecond = 242589.6
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.16989441 * 2560; err = 0.35898438 * 2560; time = 0.0105s; samplesPerSecond = 243161.1
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12214737 * 2560; err = 0.34804687 * 2560; time = 0.0106s; samplesPerSecond = 242458.7
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.12149048 * 2560; err = 0.34687500 * 2560; time = 0.0105s; samplesPerSecond = 242900.4
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19465485 * 2560; err = 0.36406250 * 2560; time = 0.0105s; samplesPerSecond = 243403.9
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.13471985 * 2560; err = 0.34140625 * 2560; time = 0.0106s; samplesPerSecond = 241320.5
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16473541 * 2560; err = 0.36054687 * 2560; time = 0.0105s; samplesPerSecond = 243089.5
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.12361755 * 2560; err = 0.35000000 * 2560; time = 0.0107s; samplesPerSecond = 239754.3
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09654999 * 2560; err = 0.34101562 * 2560; time = 0.0105s; samplesPerSecond = 243246.6
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.10468903 * 2560; err = 0.33945313 * 2560; time = 0.0105s; samplesPerSecond = 242812.8
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.11432037 * 2560; err = 0.33007813 * 2560; time = 0.0109s; samplesPerSecond = 235773.0
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.10250244 * 2560; err = 0.33906250 * 2560; time = 0.0106s; samplesPerSecond = 242438.0
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.06273804 * 2560; err = 0.32578125 * 2560; time = 0.0106s; samplesPerSecond = 242527.6
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.10996704 * 2560; err = 0.33750000 * 2560; time = 0.0105s; samplesPerSecond = 242812.8
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13582306 * 2560; err = 0.35078125 * 2560; time = 0.0108s; samplesPerSecond = 236273.5
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.12325439 * 2560; err = 0.34257813 * 2560; time = 0.0106s; samplesPerSecond = 240898.1
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10882263 * 2560; err = 0.34023437 * 2560; time = 0.0106s; samplesPerSecond = 242470.2
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09274902 * 2560; err = 0.33789063 * 2560; time = 0.0105s; samplesPerSecond = 243322.9
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.04688721 * 2560; err = 0.31914063 * 2560; time = 0.0106s; samplesPerSecond = 240456.9
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.04932556 * 2560; err = 0.33515625 * 2560; time = 0.0106s; samplesPerSecond = 242504.6
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.03842468 * 2560; err = 0.31992188 * 2560; time = 0.0105s; samplesPerSecond = 243505.7
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.06117859 * 2560; err = 0.33046875 * 2560; time = 0.0105s; samplesPerSecond = 243642.5
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.11318054 * 2560; err = 0.34492187 * 2560; time = 0.0105s; samplesPerSecond = 243468.7
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08679199 * 2560; err = 0.33515625 * 2560; time = 0.0107s; samplesPerSecond = 239276.9
01/10/2018 00:17:06:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.04743347 * 2560; err = 0.32773438 * 2560; time = 0.0105s; samplesPerSecond = 243663.3
01/10/2018 00:17:06: Finished Epoch[ 2 of 2]: [Training] ce = 1.11559134 * 81920; err = 0.34248047 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.345179s
01/10/2018 00:17:06: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

01/10/2018 00:17:07: Action "train" complete.


01/10/2018 00:17:07: ##############################################################################
01/10/2018 00:17:07: #                                                                            #
01/10/2018 00:17:07: # addLayer3 command (edit action)                                            #
01/10/2018 00:17:07: #                                                                            #
01/10/2018 00:17:07: ##############################################################################


01/10/2018 00:17:07: Action "edit" complete.


01/10/2018 00:17:07: ##############################################################################
01/10/2018 00:17:07: #                                                                            #
01/10/2018 00:17:07: # speechTrain command (train action)                                         #
01/10/2018 00:17:07: #                                                                            #
01/10/2018 00:17:07: ##############################################################################

01/10/2018 00:17:07: 
Starting from checkpoint. Loading network from 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/10/2018 00:17:07: 
Model has 29 nodes. Using GPU 0.

01/10/2018 00:17:07: Training criterion:   ce = CrossEntropyWithSoftmax
01/10/2018 00:17:07: Evaluation criterion: err = ClassificationError

01/10/2018 00:17:07: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

01/10/2018 00:17:07: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 00:17:07: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:07: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 00:17:07: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:07: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 00:17:07: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:07: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 00:17:07: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 00:17:07: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/10/2018 00:17:07: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 00:17:07: Starting minibatch loop.
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.09347076 * 2560; err = 0.82734375 * 2560; time = 0.0230s; samplesPerSecond = 111135.2
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57447586 * 2560; err = 0.64023438 * 2560; time = 0.0137s; samplesPerSecond = 186249.5
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03476105 * 2560; err = 0.54375000 * 2560; time = 0.0137s; samplesPerSecond = 187014.2
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.73747635 * 2560; err = 0.47617188 * 2560; time = 0.0137s; samplesPerSecond = 187237.2
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.55056915 * 2560; err = 0.43750000 * 2560; time = 0.0137s; samplesPerSecond = 187363.2
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.44497986 * 2560; err = 0.41054687 * 2560; time = 0.0137s; samplesPerSecond = 187305.7
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.36142731 * 2560; err = 0.40546875 * 2560; time = 0.0137s; samplesPerSecond = 186685.5
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.35946808 * 2560; err = 0.39531250 * 2560; time = 0.0137s; samplesPerSecond = 186894.1
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.34237213 * 2560; err = 0.39570312 * 2560; time = 0.0138s; samplesPerSecond = 185477.7
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30687866 * 2560; err = 0.37929687 * 2560; time = 0.0137s; samplesPerSecond = 187131.8
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31363678 * 2560; err = 0.38750000 * 2560; time = 0.0137s; samplesPerSecond = 187398.9
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.24034119 * 2560; err = 0.37109375 * 2560; time = 0.0137s; samplesPerSecond = 187385.2
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.21518860 * 2560; err = 0.35937500 * 2560; time = 0.0136s; samplesPerSecond = 187578.8
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.24078827 * 2560; err = 0.36914063 * 2560; time = 0.0136s; samplesPerSecond = 187862.3
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.23589020 * 2560; err = 0.37265625 * 2560; time = 0.0137s; samplesPerSecond = 187420.8
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.20203857 * 2560; err = 0.35351563 * 2560; time = 0.0137s; samplesPerSecond = 187026.5
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.22040405 * 2560; err = 0.36328125 * 2560; time = 0.0142s; samplesPerSecond = 180606.0
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.25242310 * 2560; err = 0.38046875 * 2560; time = 0.0137s; samplesPerSecond = 187499.1
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.27484131 * 2560; err = 0.38554688 * 2560; time = 0.0137s; samplesPerSecond = 186869.5
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.22908630 * 2560; err = 0.38554688 * 2560; time = 0.0137s; samplesPerSecond = 187368.7
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.18030090 * 2560; err = 0.36093750 * 2560; time = 0.0136s; samplesPerSecond = 187614.5
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.19837036 * 2560; err = 0.36757812 * 2560; time = 0.0136s; samplesPerSecond = 187741.1
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.22071533 * 2560; err = 0.36406250 * 2560; time = 0.0137s; samplesPerSecond = 187275.5
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.19018860 * 2560; err = 0.35351563 * 2560; time = 0.0137s; samplesPerSecond = 187049.7
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17300720 * 2560; err = 0.35742188 * 2560; time = 0.0137s; samplesPerSecond = 186958.2
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.12558594 * 2560; err = 0.35351563 * 2560; time = 0.0137s; samplesPerSecond = 187127.7
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.19316711 * 2560; err = 0.35898438 * 2560; time = 0.0145s; samplesPerSecond = 176060.0
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.13930359 * 2560; err = 0.35195312 * 2560; time = 0.0136s; samplesPerSecond = 187617.3
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12437134 * 2560; err = 0.33515625 * 2560; time = 0.0136s; samplesPerSecond = 187851.3
01/10/2018 00:17:07:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.10540161 * 2560; err = 0.34101562 * 2560; time = 0.0137s; samplesPerSecond = 186790.4
01/10/2018 00:17:08:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12473755 * 2560; err = 0.33515625 * 2560; time = 0.0136s; samplesPerSecond = 187560.9
01/10/2018 00:17:08:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.13026428 * 2560; err = 0.34765625 * 2560; time = 0.0136s; samplesPerSecond = 187673.7
01/10/2018 00:17:08: Finished Epoch[ 1 of 4]: [Training] ce = 1.41049786 * 81920; err = 0.40207520 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.575907s
01/10/2018 00:17:08: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

01/10/2018 00:17:08: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:08: Starting minibatch loop.
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.21424761 * 5120; err = 0.36523438 * 5120; time = 0.0261s; samplesPerSecond = 195828.7
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.14997759 * 5120; err = 0.34570313 * 5120; time = 0.0187s; samplesPerSecond = 274517.6
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.10502491 * 5120; err = 0.33886719 * 5120; time = 0.0185s; samplesPerSecond = 276275.9
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10657425 * 5120; err = 0.34101562 * 5120; time = 0.0185s; samplesPerSecond = 276474.3
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16255798 * 5120; err = 0.36328125 * 5120; time = 0.0185s; samplesPerSecond = 276498.2
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.15796547 * 5120; err = 0.35898438 * 5120; time = 0.0185s; samplesPerSecond = 276511.6
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.13883362 * 5120; err = 0.34492187 * 5120; time = 0.0185s; samplesPerSecond = 276710.4
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.10509262 * 5120; err = 0.34648438 * 5120; time = 0.0187s; samplesPerSecond = 274229.4
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.11047897 * 5120; err = 0.34062500 * 5120; time = 0.0185s; samplesPerSecond = 277053.3
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06133652 * 5120; err = 0.32734375 * 5120; time = 0.0185s; samplesPerSecond = 276866.0
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.10699844 * 5120; err = 0.33867188 * 5120; time = 0.0185s; samplesPerSecond = 277227.3
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.13975754 * 5120; err = 0.35292969 * 5120; time = 0.0186s; samplesPerSecond = 275719.5
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.04995117 * 5120; err = 0.32480469 * 5120; time = 0.0185s; samplesPerSecond = 276933.4
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02763824 * 5120; err = 0.32285156 * 5120; time = 0.0184s; samplesPerSecond = 277583.5
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08706665 * 5120; err = 0.32988281 * 5120; time = 0.0185s; samplesPerSecond = 277000.8
01/10/2018 00:17:08:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06690369 * 5120; err = 0.32167969 * 5120; time = 0.0185s; samplesPerSecond = 276991.8
01/10/2018 00:17:08: Finished Epoch[ 2 of 4]: [Training] ce = 1.11190033 * 81920; err = 0.34145508 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.307733s
01/10/2018 00:17:08: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

01/10/2018 00:17:08: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:08: Starting minibatch loop.
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.12241631 * 5120; err = 0.34179688 * 5120; time = 0.0199s; samplesPerSecond = 257822.8
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.08498554 * 5120; err = 0.33613281 * 5120; time = 0.0186s; samplesPerSecond = 275259.9
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09316616 * 5120; err = 0.33828125 * 5120; time = 0.0185s; samplesPerSecond = 276525.1
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10422935 * 5120; err = 0.33828125 * 5120; time = 0.0185s; samplesPerSecond = 276937.9
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07953606 * 5120; err = 0.33261719 * 5120; time = 0.0185s; samplesPerSecond = 277128.3
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.05399208 * 5120; err = 0.33085938 * 5120; time = 0.0187s; samplesPerSecond = 274386.6
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06956406 * 5120; err = 0.32539062 * 5120; time = 0.0185s; samplesPerSecond = 277475.2
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07985764 * 5120; err = 0.32792969 * 5120; time = 0.0185s; samplesPerSecond = 276595.3
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.05197220 * 5120; err = 0.32617188 * 5120; time = 0.0185s; samplesPerSecond = 276655.1
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.05977478 * 5120; err = 0.33046875 * 5120; time = 0.0184s; samplesPerSecond = 277582.0
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.04717255 * 5120; err = 0.32792969 * 5120; time = 0.0185s; samplesPerSecond = 276466.8
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08563919 * 5120; err = 0.33964844 * 5120; time = 0.0185s; samplesPerSecond = 277383.5
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.10514679 * 5120; err = 0.32910156 * 5120; time = 0.0185s; samplesPerSecond = 276997.8
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.06171722 * 5120; err = 0.32109375 * 5120; time = 0.0185s; samplesPerSecond = 277105.8
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.05704346 * 5120; err = 0.33281250 * 5120; time = 0.0185s; samplesPerSecond = 277150.8
01/10/2018 00:17:08:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.04391479 * 5120; err = 0.32871094 * 5120; time = 0.0293s; samplesPerSecond = 174596.2
01/10/2018 00:17:08: Finished Epoch[ 3 of 4]: [Training] ce = 1.07500801 * 81920; err = 0.33170166 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.311225s
01/10/2018 00:17:08: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

01/10/2018 00:17:08: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:08: Starting minibatch loop.
01/10/2018 00:17:08:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03005266 * 5120; err = 0.32695313 * 5120; time = 0.0199s; samplesPerSecond = 257537.5
01/10/2018 00:17:08:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.04017516 * 4926; err = 0.31303289 * 4926; time = 0.0605s; samplesPerSecond = 81409.9
01/10/2018 00:17:08:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02174778 * 5120; err = 0.32285156 * 5120; time = 0.0185s; samplesPerSecond = 276219.2
01/10/2018 00:17:08:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.01952095 * 5120; err = 0.31582031 * 5120; time = 0.0185s; samplesPerSecond = 276155.2
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.00513496 * 5120; err = 0.31972656 * 5120; time = 0.0185s; samplesPerSecond = 277499.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99812813 * 5120; err = 0.31367187 * 5120; time = 0.0185s; samplesPerSecond = 277149.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 0.99019432 * 5120; err = 0.30546875 * 5120; time = 0.0185s; samplesPerSecond = 277177.8
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.01111908 * 5120; err = 0.31445313 * 5120; time = 0.0185s; samplesPerSecond = 277128.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99833145 * 5120; err = 0.31289062 * 5120; time = 0.0185s; samplesPerSecond = 277219.8
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.96827850 * 5120; err = 0.31464844 * 5120; time = 0.0187s; samplesPerSecond = 273339.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 0.99143982 * 5120; err = 0.30781250 * 5120; time = 0.0185s; samplesPerSecond = 276216.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.00068130 * 5120; err = 0.31035156 * 5120; time = 0.0186s; samplesPerSecond = 274908.2
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00592957 * 5120; err = 0.31328125 * 5120; time = 0.0185s; samplesPerSecond = 277272.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.98450165 * 5120; err = 0.30976562 * 5120; time = 0.0185s; samplesPerSecond = 276289.3
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.93657532 * 5120; err = 0.29726562 * 5120; time = 0.0185s; samplesPerSecond = 277150.8
01/10/2018 00:17:09:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96798401 * 5120; err = 0.30292969 * 5120; time = 0.0185s; samplesPerSecond = 276894.5
01/10/2018 00:17:09: Finished Epoch[ 4 of 4]: [Training] ce = 0.99785318 * 81920; err = 0.31252441 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.343959s
01/10/2018 00:17:09: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech'

01/10/2018 00:17:09: Action "train" complete.


01/10/2018 00:17:09: ##############################################################################
01/10/2018 00:17:09: #                                                                            #
01/10/2018 00:17:09: # replaceCriterionNode command (edit action)                                 #
01/10/2018 00:17:09: #                                                                            #
01/10/2018 00:17:09: ##############################################################################


01/10/2018 00:17:09: Action "edit" complete.


01/10/2018 00:17:09: ##############################################################################
01/10/2018 00:17:09: #                                                                            #
01/10/2018 00:17:09: # sequenceTrain command (train action)                                       #
01/10/2018 00:17:09: #                                                                            #
01/10/2018 00:17:09: ##############################################################################

01/10/2018 00:17:09: 
Starting from checkpoint. Loading network from 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying', 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list', 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu\TestData\CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
01/10/2018 00:17:09: 
Model has 29 nodes. Using GPU 0.

01/10/2018 00:17:09: Training criterion:   ce = SequenceWithSoftmax
01/10/2018 00:17:09: Evaluation criterion: err = ClassificationError

01/10/2018 00:17:09: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

01/10/2018 00:17:09: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 00:17:09: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:09: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 00:17:09: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:09: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 00:17:09: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 00:17:09: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 00:17:09: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 00:17:09: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

01/10/2018 00:17:09: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 00:17:15: Starting minibatch loop.
dengamma value 1.098157
dengamma value 1.106251
dengamma value 1.082561
dengamma value 1.112890
dengamma value 1.058198
dengamma value 1.096610
dengamma value 1.098049
dengamma value 1.085092
dengamma value 0.994490
dengamma value 1.096401
01/10/2018 00:17:17:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.07487197 * 3030; err = 0.35049505 * 3030; time = 2.5146s; samplesPerSecond = 1205.0
dengamma value 1.032032
dengamma value 1.057598
dengamma value 1.072557
dengamma value 1.157991
dengamma value 1.070472
dengamma value 1.063513
dengamma value 1.034062
dengamma value 0.987969
dengamma value 0.950870
dengamma value 1.128985
01/10/2018 00:17:18:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08708244 * 2720; err = 0.33897059 * 2720; time = 0.2583s; samplesPerSecond = 10530.4
dengamma value 1.081391
dengamma value 1.137648
dengamma value 1.049257
dengamma value 1.077474
dengamma value 1.072234
dengamma value 1.145192
dengamma value 1.018340
dengamma value 0.963768
dengamma value 1.074528
dengamma value 0.954175
01/10/2018 00:17:18:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08986032 * 2460; err = 0.34065041 * 2460; time = 0.2189s; samplesPerSecond = 11239.4
dengamma value 1.051671
dengamma value 1.063835
dengamma value 1.044365
dengamma value 1.085000
dengamma value 1.072683
dengamma value 1.123277
dengamma value 1.052824
dengamma value 1.131793
dengamma value 1.101259
dengamma value 1.104918
01/10/2018 00:17:18:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08122982 * 3390; err = 0.28584071 * 3390; time = 0.3571s; samplesPerSecond = 9493.3
dengamma value 1.197665
dengamma value 1.110904
dengamma value 1.137528
dengamma value 1.165162
dengamma value 0.953704
dengamma value 1.096160
dengamma value 1.057111
dengamma value 1.077334
dengamma value 1.035147
dengamma value 1.087287
01/10/2018 00:17:19:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.06284136 * 2630; err = 0.32585551 * 2630; time = 0.2791s; samplesPerSecond = 9423.8
dengamma value 1.228457
dengamma value 1.062338
dengamma value 1.060767
dengamma value 1.095013
dengamma value 1.075483
dengamma value 1.105219
dengamma value 1.016098
dengamma value 1.056174
dengamma value 1.136700
dengamma value 1.075757
01/10/2018 00:17:19:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08269824 * 2640; err = 0.30075758 * 2640; time = 0.2811s; samplesPerSecond = 9391.4
dengamma value 1.073111
dengamma value 1.109574
dengamma value 1.033514
dengamma value 1.024983
dengamma value 1.002046
dengamma value 1.160107
dengamma value 1.143854
dengamma value 1.075593
dengamma value 1.104278
dengamma value 1.097520
01/10/2018 00:17:19:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08414097 * 3260; err = 0.31257669 * 3260; time = 0.3463s; samplesPerSecond = 9414.1
dengamma value 1.107276
dengamma value 1.095851
dengamma value 1.049153
dengamma value 1.062153
dengamma value 1.136648
dengamma value 1.127192
dengamma value 1.059680
dengamma value 1.041588
dengamma value 1.087930
dengamma value 1.110820
01/10/2018 00:17:19:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07776234 * 2890; err = 0.28408304 * 2890; time = 0.3218s; samplesPerSecond = 8980.3
dengamma value 1.049407
dengamma value 1.086985
dengamma value 0.977111
dengamma value 1.095410
dengamma value 1.140545
dengamma value 1.103287
dengamma value 1.172994
dengamma value 1.054062
dengamma value 1.020148
dengamma value 1.037801
01/10/2018 00:17:20:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07893793 * 2940; err = 0.35986395 * 2940; time = 0.3067s; samplesPerSecond = 9587.5
dengamma value 1.118989
dengamma value 1.066894
dengamma value 1.202222
dengamma value 1.080672
dengamma value 1.060066
dengamma value 1.114328
dengamma value 1.092812
dengamma value 1.081316
dengamma value 1.046736
dengamma value 1.129437
01/10/2018 00:17:20:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.07567014 * 2650; err = 0.26301887 * 2650; time = 0.2951s; samplesPerSecond = 8980.7
dengamma value 1.047832
dengamma value 1.054332
dengamma value 1.106057
dengamma value 1.067875
dengamma value 1.066747
dengamma value 1.159817
dengamma value 1.063600
dengamma value 1.134628
dengamma value 1.089619
dengamma value 1.033048
01/10/2018 00:17:20:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08271180 * 2410; err = 0.31576763 * 2410; time = 0.2541s; samplesPerSecond = 9483.7
dengamma value 1.075851
dengamma value 1.084133
dengamma value 1.072607
dengamma value 1.067672
dengamma value 1.081708
dengamma value 1.178889
dengamma value 1.097974
dengamma value 1.172555
dengamma value 1.055876
dengamma value 1.037180
01/10/2018 00:17:21:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.07147976 * 2700; err = 0.31444444 * 2700; time = 0.2874s; samplesPerSecond = 9394.8
dengamma value 1.015297
dengamma value 1.078042
dengamma value 1.089801
dengamma value 1.132930
dengamma value 1.106688
dengamma value 1.094006
dengamma value 1.133973
dengamma value 1.081589
dengamma value 1.126929
dengamma value 1.033561
01/10/2018 00:17:21:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08327647 * 2380; err = 0.32605042 * 2380; time = 0.2487s; samplesPerSecond = 9569.9
dengamma value 1.076193
dengamma value 0.960966
dengamma value 1.084532
dengamma value 0.979241
dengamma value 1.092376
dengamma value 1.065985
dengamma value 1.089902
dengamma value 1.128427
dengamma value 1.070220
dengamma value 1.044788
01/10/2018 00:17:21:  Epoch[ 1 of 3]-Minibatch[ 131- 140, 1.71%]: ce = 0.07500334 * 2630; err = 0.33726236 * 2630; time = 0.2988s; samplesPerSecond = 8803.3
dengamma value 1.033618
dengamma value 1.077813
dengamma value 1.089922
dengamma value 1.039080
dengamma value 1.111939
dengamma value 0.983306
dengamma value 1.097458
dengamma value 1.073135
dengamma value 1.186335
dengamma value 1.083103
01/10/2018 00:17:22:  Epoch[ 1 of 3]-Minibatch[ 141- 150, 1.83%]: ce = 0.07540905 * 3100; err = 0.29032258 * 3100; time = 0.3389s; samplesPerSecond = 9147.3
dengamma value 1.094129
dengamma value 0.935865
dengamma value 1.094436
dengamma value 1.032744
dengamma value 1.073981
dengamma value 1.088789
dengamma value 0.982670
dengamma value 0.997057
dengamma value 1.041219
dengamma value 1.088521
01/10/2018 00:17:22:  Epoch[ 1 of 3]-Minibatch[ 151- 160, 1.95%]: ce = 0.07356146 * 2720; err = 0.37500000 * 2720; time = 0.2717s; samplesPerSecond = 10012.8
dengamma value 1.187688
dengamma value 1.040984
dengamma value 1.076985
dengamma value 1.078936
dengamma value 1.071944
dengamma value 1.044442
dengamma value 1.085509
dengamma value 1.062284
dengamma value 1.103135
dengamma value 1.015508
01/10/2018 00:17:22:  Epoch[ 1 of 3]-Minibatch[ 161- 170, 2.08%]: ce = 0.08268026 * 3000; err = 0.30033333 * 3000; time = 0.2847s; samplesPerSecond = 10538.1
dengamma value 1.286482
dengamma value 1.108562
dengamma value 1.098396
dengamma value 1.128847
dengamma value 1.045091
dengamma value 1.101791
dengamma value 1.125997
dengamma value 1.079883
dengamma value 1.046293
dengamma value 1.048269
01/10/2018 00:17:22:  Epoch[ 1 of 3]-Minibatch[ 171- 180, 2.20%]: ce = 0.07047775 * 3370; err = 0.27804154 * 3370; time = 0.3510s; samplesPerSecond = 9600.9
dengamma value 1.078788
dengamma value 1.107343
dengamma value 1.101204
dengamma value 0.960008
dengamma value 1.107882
dengamma value 1.007515
dengamma value 1.109840
dengamma value 1.008014
dengamma value 1.133813
dengamma value 1.104308
01/10/2018 00:17:23:  Epoch[ 1 of 3]-Minibatch[ 181- 190, 2.32%]: ce = 0.07960787 * 2600; err = 0.35576923 * 2600; time = 0.2852s; samplesPerSecond = 9117.2
dengamma value 1.105338
dengamma value 1.129334
dengamma value 1.083165
dengamma value 1.038746
dengamma value 1.086768
dengamma value 1.026720
dengamma value 1.152656
dengamma value 0.983740
dengamma value 1.155358
dengamma value 1.011313
01/10/2018 00:17:23:  Epoch[ 1 of 3]-Minibatch[ 191- 200, 2.44%]: ce = 0.07935434 * 2600; err = 0.31230769 * 2600; time = 0.2734s; samplesPerSecond = 9508.2
dengamma value 1.087543
dengamma value 1.053718
dengamma value 0.985794
dengamma value 1.085655
dengamma value 1.099306
dengamma value 1.024260
dengamma value 1.049562
dengamma value 1.138642
dengamma value 1.159902
dengamma value 1.158625
01/10/2018 00:17:23:  Epoch[ 1 of 3]-Minibatch[ 201- 210, 2.56%]: ce = 0.07102263 * 2300; err = 0.33260870 * 2300; time = 0.2515s; samplesPerSecond = 9144.7
dengamma value 1.012161
dengamma value 1.024525
dengamma value 1.001728
dengamma value 1.089635
dengamma value 1.041389
dengamma value 1.075765
dengamma value 1.192685
dengamma value 1.028642
dengamma value 1.091593
dengamma value 1.069779
01/10/2018 00:17:24:  Epoch[ 1 of 3]-Minibatch[ 211- 220, 2.69%]: ce = 0.08151838 * 2800; err = 0.34357143 * 2800; time = 0.2986s; samplesPerSecond = 9376.2
dengamma value 1.068428
dengamma value 1.109537
dengamma value 1.106124
dengamma value 1.082162
dengamma value 1.005531
dengamma value 1.004299
dengamma value 1.072272
dengamma value 1.071440
dengamma value 1.101832
dengamma value 1.022549
01/10/2018 00:17:24:  Epoch[ 1 of 3]-Minibatch[ 221- 230, 2.81%]: ce = 0.08598953 * 2590; err = 0.32741313 * 2590; time = 0.2681s; samplesPerSecond = 9659.4
dengamma value 0.995574
dengamma value 1.093792
dengamma value 1.106915
dengamma value 1.114396
dengamma value 1.075629
dengamma value 1.086284
dengamma value 0.998504
dengamma value 1.141893
dengamma value 1.112956
dengamma value 1.105446
01/10/2018 00:17:24:  Epoch[ 1 of 3]-Minibatch[ 231- 240, 2.93%]: ce = 0.07584692 * 2610; err = 0.30919540 * 2610; time = 0.2703s; samplesPerSecond = 9655.7
dengamma value 1.142979
dengamma value 1.094858
dengamma value 1.112932
dengamma value 1.111596
dengamma value 1.057984
dengamma value 1.131579
dengamma value 1.132749
dengamma value 1.042995
dengamma value 1.076826
dengamma value 1.024062
01/10/2018 00:17:24:  Epoch[ 1 of 3]-Minibatch[ 241- 250, 3.05%]: ce = 0.07877686 * 2400; err = 0.30875000 * 2400; time = 0.2361s; samplesPerSecond = 10164.9
dengamma value 1.121445
dengamma value 1.079991
dengamma value 1.092558
dengamma value 1.076313
dengamma value 1.071288
dengamma value 1.067850
dengamma value 1.171702
dengamma value 1.094304
dengamma value 1.058888
dengamma value 1.036921
01/10/2018 00:17:25:  Epoch[ 1 of 3]-Minibatch[ 251- 260, 3.17%]: ce = 0.07854553 * 3200; err = 0.28656250 * 3200; time = 0.3345s; samplesPerSecond = 9567.8
dengamma value 1.105200
dengamma value 1.063137
dengamma value 1.130558
dengamma value 1.083695
dengamma value 1.120837
dengamma value 1.048910
dengamma value 1.085424
dengamma value 1.056437
dengamma value 1.121678
dengamma value 1.010441
01/10/2018 00:17:25:  Epoch[ 1 of 3]-Minibatch[ 261- 270, 3.30%]: ce = 0.08404989 * 3570; err = 0.30028011 * 3570; time = 0.3986s; samplesPerSecond = 8955.6
dengamma value 1.031804
dengamma value 1.141028
dengamma value 1.114967
dengamma value 1.049522
dengamma value 1.084649
dengamma value 1.013246
dengamma value 1.059282
dengamma value 1.127644
dengamma value 0.973975
dengamma value 1.078594
01/10/2018 00:17:25:  Epoch[ 1 of 3]-Minibatch[ 271- 280, 3.42%]: ce = 0.09594299 * 2510; err = 0.34860558 * 2510; time = 0.2403s; samplesPerSecond = 10444.5
dengamma value 1.045329
dengamma value 1.099711
dengamma value 0.935432
dengamma value 1.093521
dengamma value 1.095008
dengamma value 1.073385
dengamma value 1.103955
dengamma value 1.058324
dengamma value 1.066021
dengamma value 1.084483
01/10/2018 00:17:26:  Epoch[ 1 of 3]-Minibatch[ 281- 290, 3.54%]: ce = 0.07402617 * 3400; err = 0.36911765 * 3400; time = 0.3540s; samplesPerSecond = 9605.0
dengamma value 1.144046
dengamma value 1.080928
dengamma value 1.027465
01/10/2018 00:17:26: Finished Epoch[ 1 of 3]: [Training] ce = 0.07898496 * 82104; err = 0.31997223 * 82104; totalSamplesSeen = 82104; learningRatePerSample = 2e-06; epochTime=16.3606s
01/10/2018 00:17:26: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

01/10/2018 00:17:26: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82104), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:26: Starting minibatch loop.
dengamma value 1.094192
dengamma value 1.082099
dengamma value 1.055784
dengamma value 0.961069
dengamma value 1.143452
dengamma value 1.076682
dengamma value 1.079352
dengamma value 1.077103
dengamma value 1.068353
dengamma value 1.050263
01/10/2018 00:17:26:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08315414 * 2880; err = 0.29791667 * 2880; time = 0.2826s; samplesPerSecond = 10190.9
dengamma value 1.058989
dengamma value 1.126660
dengamma value 1.052224
dengamma value 1.038817
dengamma value 1.084766
dengamma value 1.077397
dengamma value 1.062587
dengamma value 1.071580
dengamma value 1.076107
dengamma value 1.109994
01/10/2018 00:17:26:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.07810943 * 2560; err = 0.29765625 * 2560; time = 0.2645s; samplesPerSecond = 9678.8
dengamma value 1.065765
dengamma value 1.067516
dengamma value 1.067111
dengamma value 1.200090
dengamma value 1.036868
dengamma value 1.073525
dengamma value 1.040210
dengamma value 1.041021
dengamma value 1.126510
dengamma value 1.046665
01/10/2018 00:17:27:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08311300 * 2240; err = 0.32544643 * 2240; time = 0.2387s; samplesPerSecond = 9384.6
dengamma value 1.062636
dengamma value 1.011486
dengamma value 1.093481
dengamma value 1.105808
dengamma value 1.021724
dengamma value 1.019951
dengamma value 1.034297
dengamma value 1.111909
dengamma value 1.033059
dengamma value 1.057929
01/10/2018 00:17:27:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08859492 * 2940; err = 0.30952381 * 2940; time = 0.3180s; samplesPerSecond = 9246.5
dengamma value 1.095891
dengamma value 1.048078
dengamma value 1.083873
dengamma value 1.069195
dengamma value 1.089107
dengamma value 1.071511
dengamma value 1.083502
dengamma value 1.068608
dengamma value 1.044492
dengamma value 1.081681
01/10/2018 00:17:27:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08273410 * 2570; err = 0.31906615 * 2570; time = 0.2417s; samplesPerSecond = 10634.8
dengamma value 1.019873
dengamma value 1.037871
dengamma value 1.095674
dengamma value 1.057900
dengamma value 1.090767
dengamma value 1.064899
dengamma value 1.007462
dengamma value 1.063698
dengamma value 1.036106
dengamma value 1.041405
01/10/2018 00:17:27:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08371552 * 2800; err = 0.29071429 * 2800; time = 0.2749s; samplesPerSecond = 10187.1
dengamma value 1.011848
dengamma value 1.046794
dengamma value 1.031635
dengamma value 1.083332
dengamma value 1.013357
dengamma value 1.114831
dengamma value 1.142379
dengamma value 1.064662
dengamma value 1.160959
dengamma value 1.151135
01/10/2018 00:17:28:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07670466 * 2540; err = 0.27204724 * 2540; time = 0.2849s; samplesPerSecond = 8914.6
dengamma value 1.060599
dengamma value 1.085287
dengamma value 1.099561
dengamma value 1.014757
dengamma value 0.994656
dengamma value 1.086714
dengamma value 1.040621
dengamma value 0.974319
dengamma value 1.033122
dengamma value 1.087092
01/10/2018 00:17:28:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08128438 * 2180; err = 0.36100917 * 2180; time = 0.2082s; samplesPerSecond = 10471.3
dengamma value 1.038360
dengamma value 1.032494
dengamma value 0.990200
dengamma value 0.991864
dengamma value 1.125399
dengamma value 1.130266
dengamma value 1.066020
dengamma value 1.152656
dengamma value 1.073778
dengamma value 1.021275
01/10/2018 00:17:28:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.09045466 * 3060; err = 0.32875817 * 3060; time = 0.3128s; samplesPerSecond = 9782.2
dengamma value 1.091784
dengamma value 1.115456
dengamma value 1.096193
dengamma value 1.044564
dengamma value 1.163755
dengamma value 1.069460
dengamma value 1.062514
dengamma value 1.023144
dengamma value 0.933032
dengamma value 1.007834
01/10/2018 00:17:29:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08035208 * 3280; err = 0.32469512 * 3280; time = 0.3460s; samplesPerSecond = 9479.4
dengamma value 1.081170
dengamma value 1.009058
dengamma value 1.140225
dengamma value 1.046304
dengamma value 1.020039
dengamma value 1.030756
dengamma value 1.070017
dengamma value 1.069935
dengamma value 1.062697
dengamma value 1.036778
01/10/2018 00:17:29:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08731439 * 3270; err = 0.30795107 * 3270; time = 0.3414s; samplesPerSecond = 9579.1
dengamma value 1.094432
dengamma value 1.014554
dengamma value 1.053956
dengamma value 1.052139
dengamma value 1.119733
dengamma value 1.080540
dengamma value 1.044666
dengamma value 1.102464
dengamma value 1.118225
dengamma value 1.075555
01/10/2018 00:17:29:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08665724 * 2560; err = 0.30585937 * 2560; time = 0.2892s; samplesPerSecond = 8851.3
dengamma value 1.049400
dengamma value 1.077216
dengamma value 1.065106
dengamma value 1.071094
dengamma value 1.089589
dengamma value 0.998683
dengamma value 1.116511
dengamma value 1.054096
dengamma value 1.029180
dengamma value 1.070048
01/10/2018 00:17:29:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.07761127 * 2820; err = 0.32304965 * 2820; time = 0.2916s; samplesPerSecond = 9669.2
dengamma value 1.052674
dengamma value 1.037336
dengamma value 1.054958
dengamma value 1.026641
dengamma value 1.162028
dengamma value 1.015970
dengamma value 1.028912
dengamma value 1.015787
dengamma value 1.053263
dengamma value 1.055796
01/10/2018 00:17:30:  Epoch[ 2 of 3]-Minibatch[ 131- 140, 1.71%]: ce = 0.08799373 * 2420; err = 0.37148760 * 2420; time = 0.2529s; samplesPerSecond = 9569.6
dengamma value 1.043489
dengamma value 1.060638
dengamma value 1.046106
dengamma value 1.057764
dengamma value 1.076539
dengamma value 1.070210
dengamma value 1.034367
dengamma value 1.078990
dengamma value 1.080894
dengamma value 1.031643
01/10/2018 00:17:30:  Epoch[ 2 of 3]-Minibatch[ 141- 150, 1.83%]: ce = 0.07695396 * 2040; err = 0.34607843 * 2040; time = 0.2174s; samplesPerSecond = 9381.8
dengamma value 1.043923
dengamma value 1.100843
dengamma value 1.052030
dengamma value 1.115294
dengamma value 1.080540
dengamma value 1.002472
dengamma value 1.117373
dengamma value 1.018227
dengamma value 0.957393
dengamma value 1.127905
01/10/2018 00:17:30:  Epoch[ 2 of 3]-Minibatch[ 151- 160, 1.95%]: ce = 0.08385918 * 3130; err = 0.34728435 * 3130; time = 0.3194s; samplesPerSecond = 9800.9
dengamma value 1.072353
dengamma value 1.152211
dengamma value 1.076150
dengamma value 1.066050
dengamma value 1.012639
dengamma value 1.071508
dengamma value 1.050148
dengamma value 1.100260
dengamma value 0.984806
dengamma value 1.077242
01/10/2018 00:17:31:  Epoch[ 2 of 3]-Minibatch[ 161- 170, 2.08%]: ce = 0.08537635 * 2600; err = 0.32615385 * 2600; time = 0.2909s; samplesPerSecond = 8936.8
dengamma value 1.065497
dengamma value 1.014835
dengamma value 1.054527
dengamma value 0.997694
dengamma value 1.046342
dengamma value 1.035061
dengamma value 0.982002
dengamma value 1.029836
dengamma value 1.095771
dengamma value 1.040110
01/10/2018 00:17:31:  Epoch[ 2 of 3]-Minibatch[ 171- 180, 2.20%]: ce = 0.09294893 * 2340; err = 0.35897436 * 2340; time = 0.2432s; samplesPerSecond = 9623.6
dengamma value 1.098093
dengamma value 1.096183
dengamma value 1.084598
dengamma value 1.105096
dengamma value 1.079621
dengamma value 1.027382
dengamma value 1.033223
dengamma value 1.049519
dengamma value 1.091064
dengamma value 0.878330
01/10/2018 00:17:31:  Epoch[ 2 of 3]-Minibatch[ 181- 190, 2.32%]: ce = 0.08367793 * 2590; err = 0.35405405 * 2590; time = 0.2639s; samplesPerSecond = 9813.2
dengamma value 1.163649
dengamma value 1.129154
dengamma value 0.987804
dengamma value 1.046962
dengamma value 1.026988
dengamma value 1.029669
dengamma value 1.033893
dengamma value 1.067522
dengamma value 1.071581
dengamma value 1.099663
01/10/2018 00:17:31:  Epoch[ 2 of 3]-Minibatch[ 191- 200, 2.44%]: ce = 0.08923007 * 2640; err = 0.31250000 * 2640; time = 0.2799s; samplesPerSecond = 9431.2
dengamma value 1.113609
dengamma value 1.111826
dengamma value 1.021733
dengamma value 1.086493
dengamma value 1.024932
dengamma value 1.157093
dengamma value 1.038879
dengamma value 1.142718
dengamma value 1.099372
dengamma value 1.078189
01/10/2018 00:17:32:  Epoch[ 2 of 3]-Minibatch[ 201- 210, 2.56%]: ce = 0.08704989 * 2840; err = 0.28767606 * 2840; time = 0.2932s; samplesPerSecond = 9687.6
dengamma value 1.037885
dengamma value 1.015264
dengamma value 1.032366
dengamma value 1.076017
dengamma value 1.030969
dengamma value 1.090328
dengamma value 1.106653
dengamma value 0.953508
dengamma value 1.028544
dengamma value 1.081440
01/10/2018 00:17:32:  Epoch[ 2 of 3]-Minibatch[ 211- 220, 2.69%]: ce = 0.08429847 * 2450; err = 0.35673469 * 2450; time = 0.2515s; samplesPerSecond = 9742.6
dengamma value 1.110429
dengamma value 1.050651
dengamma value 1.077529
dengamma value 1.046701
dengamma value 1.117976
dengamma value 1.117775
dengamma value 1.088426
dengamma value 1.053814
dengamma value 1.091510
dengamma value 1.027723
01/10/2018 00:17:32:  Epoch[ 2 of 3]-Minibatch[ 221- 230, 2.81%]: ce = 0.08785899 * 3180; err = 0.29937107 * 3180; time = 0.3236s; samplesPerSecond = 9827.9
dengamma value 0.965819
dengamma value 1.128063
dengamma value 1.047738
dengamma value 1.053374
dengamma value 1.024404
dengamma value 1.098594
dengamma value 1.024423
dengamma value 1.089020
dengamma value 0.999383
dengamma value 1.080306
01/10/2018 00:17:33:  Epoch[ 2 of 3]-Minibatch[ 231- 240, 2.93%]: ce = 0.08477680 * 2970; err = 0.31784512 * 2970; time = 0.3398s; samplesPerSecond = 8740.2
dengamma value 1.088564
dengamma value 1.055055
dengamma value 1.090746
dengamma value 1.115948
dengamma value 1.051951
dengamma value 1.035624
dengamma value 1.055674
dengamma value 1.028023
dengamma value 1.015737
dengamma value 1.085563
01/10/2018 00:17:33:  Epoch[ 2 of 3]-Minibatch[ 241- 250, 3.05%]: ce = 0.08539280 * 2830; err = 0.28409894 * 2830; time = 0.2905s; samplesPerSecond = 9742.4
dengamma value 1.016386
dengamma value 1.099158
dengamma value 1.105641
dengamma value 1.041135
dengamma value 1.142297
dengamma value 0.968866
dengamma value 1.057823
dengamma value 1.030949
dengamma value 1.062884
dengamma value 1.129589
01/10/2018 00:17:33:  Epoch[ 2 of 3]-Minibatch[ 251- 260, 3.17%]: ce = 0.08069712 * 2600; err = 0.32769231 * 2600; time = 0.2560s; samplesPerSecond = 10155.2
dengamma value 1.143103
dengamma value 1.064882
dengamma value 1.126354
dengamma value 1.087589
dengamma value 1.096430
dengamma value 1.113808
dengamma value 1.084879
dengamma value 1.110359
dengamma value 1.151112
dengamma value 1.128744
01/10/2018 00:17:33:  Epoch[ 2 of 3]-Minibatch[ 261- 270, 3.30%]: ce = 0.07569170 * 2770; err = 0.26137184 * 2770; time = 0.3052s; samplesPerSecond = 9075.6
dengamma value 1.063606
dengamma value 1.046325
dengamma value 1.115843
dengamma value 1.036365
dengamma value 1.136702
dengamma value 1.102451
dengamma value 1.196636
dengamma value 1.043793
dengamma value 1.136444
dengamma value 1.137861
01/10/2018 00:17:34:  Epoch[ 2 of 3]-Minibatch[ 271- 280, 3.42%]: ce = 0.07820831 * 2450; err = 0.30122449 * 2450; time = 0.2828s; samplesPerSecond = 8662.6
dengamma value 0.973563
dengamma value 1.017829
dengamma value 1.095241
dengamma value 1.122787
dengamma value 1.076464
dengamma value 1.052412
dengamma value 1.084082
dengamma value 1.067096
dengamma value 1.092503
dengamma value 1.131919
01/10/2018 00:17:34:  Epoch[ 2 of 3]-Minibatch[ 281- 290, 3.54%]: ce = 0.08181769 * 2730; err = 0.31428571 * 2730; time = 0.2751s; samplesPerSecond = 9923.8
dengamma value 1.098246
dengamma value 1.007781
dengamma value 1.032259
dengamma value 0.977547
dengamma value 1.033669
dengamma value 1.007694
dengamma value 1.022083
dengamma value 1.037810
dengamma value 1.081071
dengamma value 1.015176
01/10/2018 00:17:34:  Epoch[ 2 of 3]-Minibatch[ 291- 300, 3.66%]: ce = 0.08882496 * 2440; err = 0.32909836 * 2440; time = 0.2503s; samplesPerSecond = 9747.1
dengamma value 1.067903
dengamma value 1.049409
dengamma value 0.993449
dengamma value 1.064031
01/10/2018 00:17:34: Finished Epoch[ 2 of 3]: [Training] ce = 0.08392263 * 81852; err = 0.31784196 * 81852; totalSamplesSeen = 163956; learningRatePerSample = 2e-06; epochTime=8.54157s
01/10/2018 00:17:34: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

01/10/2018 00:17:34: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163956), data subset 0 of 1, with 1 datapasses

01/10/2018 00:17:34: Starting minibatch loop.
dengamma value 1.120536
dengamma value 1.043034
dengamma value 0.935201
dengamma value 1.053504
dengamma value 1.054135
dengamma value 1.063120
dengamma value 1.086814
dengamma value 1.088886
dengamma value 1.071581
dengamma value 0.997326
01/10/2018 00:17:35:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08958213 * 2810; err = 0.30533808 * 2810; time = 0.2933s; samplesPerSecond = 9580.5
dengamma value 1.023479
dengamma value 1.167924
dengamma value 1.092052
dengamma value 1.099558
dengamma value 1.102921
dengamma value 1.037780
dengamma value 1.206039
dengamma value 1.149521
dengamma value 1.097699
dengamma value 1.028733
01/10/2018 00:17:35:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.07561535 * 1970; err = 0.31421320 * 1970; time = 0.2061s; samplesPerSecond = 9560.5
dengamma value 1.100380
dengamma value 1.064007
dengamma value 1.056242
dengamma value 1.032431
dengamma value 1.101903
dengamma value 1.091928
dengamma value 1.049669
dengamma value 1.066411
dengamma value 1.026510
dengamma value 1.078377
01/10/2018 00:17:35:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08243537 * 3050; err = 0.31311475 * 3050; time = 0.3044s; samplesPerSecond = 10018.8
dengamma value 1.001786
dengamma value 1.063861
dengamma value 1.065958
dengamma value 1.017980
dengamma value 1.169641
dengamma value 1.002860
dengamma value 1.014372
dengamma value 1.085655
dengamma value 1.088683
dengamma value 1.017912
01/10/2018 00:17:35:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08938894 * 2230; err = 0.33901345 * 2230; time = 0.2404s; samplesPerSecond = 9274.4
dengamma value 1.027935
dengamma value 1.084787
dengamma value 1.037455
dengamma value 1.026124
dengamma value 1.122935
dengamma value 1.076638
dengamma value 1.059120
dengamma value 1.032678
dengamma value 1.007482
dengamma value 1.057958
01/10/2018 00:17:36:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08795322 * 2350; err = 0.33148936 * 2350; time = 0.2481s; samplesPerSecond = 9472.2
dengamma value 1.107206
dengamma value 0.998052
dengamma value 1.079846
dengamma value 1.069912
dengamma value 1.066003
dengamma value 1.085437
dengamma value 1.078553
dengamma value 1.113238
dengamma value 1.039846
dengamma value 0.990899
01/10/2018 00:17:36:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08560410 * 2850; err = 0.31578947 * 2850; time = 0.2958s; samplesPerSecond = 9633.4
dengamma value 1.009666
dengamma value 1.093568
dengamma value 1.073803
dengamma value 1.121710
dengamma value 1.063168
dengamma value 1.111108
dengamma value 1.111662
dengamma value 1.122063
dengamma value 1.033203
dengamma value 1.141327
01/10/2018 00:17:36:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07951333 * 3020; err = 0.29635762 * 3020; time = 0.3587s; samplesPerSecond = 8418.2
dengamma value 1.098909
dengamma value 0.981961
dengamma value 1.084230
dengamma value 1.104820
dengamma value 0.947825
dengamma value 1.036321
dengamma value 1.047483
dengamma value 1.016064
dengamma value 1.072944
dengamma value 1.014034
01/10/2018 00:17:37:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.09441622 * 2220; err = 0.31441441 * 2220; time = 0.2165s; samplesPerSecond = 10252.2
dengamma value 1.059296
dengamma value 1.047792
dengamma value 1.136270
dengamma value 1.173222
dengamma value 1.129351
dengamma value 1.031601
dengamma value 1.069307
dengamma value 1.139293
dengamma value 1.056081
dengamma value 1.064902
01/10/2018 00:17:37:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08509286 * 3110; err = 0.26881029 * 3110; time = 0.3697s; samplesPerSecond = 8411.7
dengamma value 1.022196
dengamma value 0.990125
dengamma value 1.014402
dengamma value 1.033788
dengamma value 1.057174
dengamma value 1.096375
dengamma value 1.008563
dengamma value 1.050195
dengamma value 1.149007
dengamma value 1.030818
01/10/2018 00:17:37:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.07650480 * 2560; err = 0.34804687 * 2560; time = 0.2715s; samplesPerSecond = 9428.6
dengamma value 1.036104
dengamma value 1.095000
dengamma value 1.166921
dengamma value 1.135808
dengamma value 1.090107
dengamma value 1.045368
dengamma value 1.083045
dengamma value 1.052756
dengamma value 1.093207
dengamma value 1.021930
01/10/2018 00:17:37:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.07994060 * 2780; err = 0.31906475 * 2780; time = 0.2852s; samplesPerSecond = 9747.3
dengamma value 1.014628
dengamma value 1.119380
dengamma value 1.123704
dengamma value 0.966645
dengamma value 0.960421
dengamma value 1.072525
dengamma value 1.060955
dengamma value 1.037380
dengamma value 1.098809
dengamma value 1.051219
01/10/2018 00:17:38:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.09093269 * 2520; err = 0.31865079 * 2520; time = 0.2759s; samplesPerSecond = 9132.5
dengamma value 1.053188
dengamma value 1.026728
dengamma value 0.968937
dengamma value 1.110307
dengamma value 1.096449
dengamma value 1.014478
dengamma value 1.064246
dengamma value 1.127211
dengamma value 1.128247
dengamma value 1.066037
01/10/2018 00:17:38:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08628867 * 2580; err = 0.31744186 * 2580; time = 0.2595s; samplesPerSecond = 9942.5
dengamma value 1.039189
dengamma value 1.093105
dengamma value 1.010951
dengamma value 1.107778
dengamma value 1.057101
dengamma value 1.102175
dengamma value 1.118991
dengamma value 1.000915
dengamma value 1.091334
dengamma value 0.984076
01/10/2018 00:17:38:  Epoch[ 3 of 3]-Minibatch[ 131- 140, 1.71%]: ce = 0.07925472 * 2450; err = 0.32612245 * 2450; time = 0.2252s; samplesPerSecond = 10881.0
dengamma value 0.972561
dengamma value 1.044718
dengamma value 1.036504
dengamma value 1.134353
dengamma value 1.027725
dengamma value 1.052530
dengamma value 1.122627
dengamma value 0.980667
dengamma value 1.058502
dengamma value 1.082974
01/10/2018 00:17:38:  Epoch[ 3 of 3]-Minibatch[ 141- 150, 1.83%]: ce = 0.08384024 * 2290; err = 0.31135371 * 2290; time = 0.2173s; samplesPerSecond = 10538.6
dengamma value 1.270468
dengamma value 1.044149
dengamma value 0.995428
dengamma value 1.084678
dengamma value 1.102933
dengamma value 1.061082
dengamma value 1.005238
dengamma value 1.079382
dengamma value 1.110160
dengamma value 1.060600
01/10/2018 00:17:39:  Epoch[ 3 of 3]-Minibatch[ 151- 160, 1.95%]: ce = 0.08121069 * 3000; err = 0.28066667 * 3000; time = 0.2910s; samplesPerSecond = 10308.2
dengamma value 1.274211
dengamma value 1.098453
dengamma value 1.071518
dengamma value 1.091137
dengamma value 0.937688
dengamma value 1.056207
dengamma value 1.077145
dengamma value 1.062990
dengamma value 0.999550
dengamma value 1.099108
01/10/2018 00:17:39:  Epoch[ 3 of 3]-Minibatch[ 161- 170, 2.08%]: ce = 0.07624794 * 2510; err = 0.30996016 * 2510; time = 0.2362s; samplesPerSecond = 10625.0
dengamma value 1.012179
dengamma value 1.093297
dengamma value 1.014935
dengamma value 1.061754
dengamma value 1.079969
dengamma value 1.074486
dengamma value 1.030915
dengamma value 1.137582
dengamma value 1.123346
dengamma value 1.078667
01/10/2018 00:17:39:  Epoch[ 3 of 3]-Minibatch[ 171- 180, 2.20%]: ce = 0.08522650 * 2610; err = 0.28084291 * 2610; time = 0.2835s; samplesPerSecond = 9206.8
dengamma value 1.104299
dengamma value 1.091328
dengamma value 1.109522
dengamma value 1.091829
dengamma value 1.000546
dengamma value 1.098479
dengamma value 1.035614
dengamma value 1.069825
dengamma value 1.082284
dengamma value 1.065267
01/10/2018 00:17:40:  Epoch[ 3 of 3]-Minibatch[ 181- 190, 2.32%]: ce = 0.08484863 * 2400; err = 0.30625000 * 2400; time = 0.2579s; samplesPerSecond = 9307.7
dengamma value 1.140037
dengamma value 1.094068
dengamma value 1.082963
dengamma value 1.075658
dengamma value 1.063642
dengamma value 1.029329
dengamma value 1.073546
dengamma value 1.084057
dengamma value 1.039129
dengamma value 1.070681
01/10/2018 00:17:40:  Epoch[ 3 of 3]-Minibatch[ 191- 200, 2.44%]: ce = 0.08464780 * 2590; err = 0.26177606 * 2590; time = 0.2813s; samplesPerSecond = 9207.8
dengamma value 1.146614
dengamma value 1.038004
dengamma value 1.083464
dengamma value 1.016419
dengamma value 1.097390
dengamma value 1.068822
dengamma value 1.091391
dengamma value 1.058538
dengamma value 0.997856
dengamma value 1.074920
01/10/2018 00:17:40:  Epoch[ 3 of 3]-Minibatch[ 201- 210, 2.56%]: ce = 0.07541663 * 2460; err = 0.36747967 * 2460; time = 0.2657s; samplesPerSecond = 9258.8
dengamma value 1.059935
dengamma value 1.127297
dengamma value 1.029912
dengamma value 1.089471
dengamma value 1.108323
dengamma value 1.015650
dengamma value 1.052023
dengamma value 1.083768
dengamma value 1.005844
dengamma value 1.049971
01/10/2018 00:17:40:  Epoch[ 3 of 3]-Minibatch[ 211- 220, 2.69%]: ce = 0.07925343 * 2810; err = 0.30249110 * 2810; time = 0.2693s; samplesPerSecond = 10436.3
dengamma value 1.047816
dengamma value 1.037694
dengamma value 1.044386
dengamma value 1.061331
dengamma value 1.085604
dengamma value 1.161612
dengamma value 1.166876
dengamma value 1.023758
dengamma value 1.017098
dengamma value 1.004604
01/10/2018 00:17:41:  Epoch[ 3 of 3]-Minibatch[ 221- 230, 2.81%]: ce = 0.08722063 * 2550; err = 0.31137255 * 2550; time = 0.2486s; samplesPerSecond = 10258.1
dengamma value 1.082435
dengamma value 1.051687
dengamma value 1.045112
dengamma value 1.051119
dengamma value 1.081021
dengamma value 1.082898
dengamma value 0.985309
dengamma value 1.005695
dengamma value 1.074795
dengamma value 1.064292
01/10/2018 00:17:41:  Epoch[ 3 of 3]-Minibatch[ 231- 240, 2.93%]: ce = 0.08834467 * 2810; err = 0.29750890 * 2810; time = 0.3096s; samplesPerSecond = 9077.6
dengamma value 1.175846
dengamma value 0.951798
dengamma value 1.039765
dengamma value 1.119797
dengamma value 1.013306
dengamma value 0.997320
dengamma value 0.978129
dengamma value 1.112122
dengamma value 1.037125
dengamma value 1.024721
01/10/2018 00:17:41:  Epoch[ 3 of 3]-Minibatch[ 241- 250, 3.05%]: ce = 0.09173997 * 2540; err = 0.32322835 * 2540; time = 0.2557s; samplesPerSecond = 9934.8
dengamma value 1.091922
dengamma value 1.061260
dengamma value 1.028855
dengamma value 1.042079
dengamma value 1.078928
dengamma value 1.061462
dengamma value 1.048656
dengamma value 1.066598
dengamma value 1.070862
dengamma value 1.015405
01/10/2018 00:17:41:  Epoch[ 3 of 3]-Minibatch[ 251- 260, 3.17%]: ce = 0.09247277 * 2790; err = 0.30501792 * 2790; time = 0.3067s; samplesPerSecond = 9096.3
dengamma value 1.093721
dengamma value 1.083641
dengamma value 1.042251
dengamma value 1.132590
dengamma value 1.061812
dengamma value 1.080220
dengamma value 1.104547
dengamma value 1.109683
dengamma value 1.082076
dengamma value 1.053906
01/10/2018 00:17:42:  Epoch[ 3 of 3]-Minibatch[ 261- 270, 3.30%]: ce = 0.08268433 * 3920; err = 0.26760204 * 3920; time = 0.4654s; samplesPerSecond = 8423.1
dengamma value 1.122059
dengamma value 1.005782
dengamma value 1.023124
dengamma value 1.070231
dengamma value 1.049399
dengamma value 1.056142
dengamma value 1.081642
dengamma value 1.030790
dengamma value 1.039016
dengamma value 1.042062
01/10/2018 00:17:42:  Epoch[ 3 of 3]-Minibatch[ 271- 280, 3.42%]: ce = 0.07723363 * 3370; err = 0.33916914 * 3370; time = 0.3308s; samplesPerSecond = 10188.5
dengamma value 1.046651
dengamma value 1.047353
dengamma value 1.033298
dengamma value 1.069368
dengamma value 1.086779
dengamma value 1.058958
dengamma value 1.017120
dengamma value 1.097401
dengamma value 1.070772
dengamma value 1.071142
01/10/2018 00:17:43:  Epoch[ 3 of 3]-Minibatch[ 281- 290, 3.54%]: ce = 0.09768141 * 2930; err = 0.30375427 * 2930; time = 0.3278s; samplesPerSecond = 8937.3
dengamma value 1.021346
dengamma value 1.027858
dengamma value 1.040996
dengamma value 1.066689
dengamma value 1.117846
dengamma value 1.140250
dengamma value 1.072074
dengamma value 1.026997
dengamma value 1.035705
dengamma value 1.037658
01/10/2018 00:17:43:  Epoch[ 3 of 3]-Minibatch[ 291- 300, 3.66%]: ce = 0.07993258 * 2590; err = 0.29806950 * 2590; time = 0.2696s; samplesPerSecond = 9605.4
dengamma value 1.044984
dengamma value 1.092996
dengamma value 1.035757
dengamma value 1.047226
dengamma value 1.055431
01/10/2018 00:17:43: Finished Epoch[ 3 of 3]: [Training] ce = 0.08408191 * 82070; err = 0.30874863 * 82070; totalSamplesSeen = 246026; learningRatePerSample = 2e-06; epochTime=8.61185s
01/10/2018 00:17:43: SGD: Saving checkpoint model 'D:\cntk-test-20180110001653.676476\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

01/10/2018 00:17:43: Action "train" complete.

01/10/2018 00:17:43: __COMPLETED__