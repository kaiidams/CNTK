CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/gpu/debug/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk currentDirectory=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData RunDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu DataDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining OutputDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu DeviceId=0 timestamping=true
CNTK 2.3.1+ (HEAD 18ebb6, Jan 10 2018 19:31:24) at 2018/01/10 19:42:26

/home/ubuntu/workspace/build/gpu/debug/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk  currentDirectory=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData  RunDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu  DataDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining  OutputDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu  DeviceId=0  timestamping=true
Changed current directory to /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
01/10/2018 19:42:26: -------------------------------------------------------------------
01/10/2018 19:42:26: Build info: 

01/10/2018 19:42:26: 		Built time: Jan 10 2018 19:29:22
01/10/2018 19:42:26: 		Last modified date: Tue Jan  9 20:16:18 2018
01/10/2018 19:42:26: 		Build type: debug
01/10/2018 19:42:26: 		Build target: GPU
01/10/2018 19:42:26: 		With 1bit-SGD: no
01/10/2018 19:42:26: 		With ASGD: yes
01/10/2018 19:42:26: 		Math lib: mkl
01/10/2018 19:42:26: 		CUDA version: 9.0.0
01/10/2018 19:42:26: 		CUDNN version: 6.0.21
01/10/2018 19:42:26: 		Build Branch: HEAD
01/10/2018 19:42:26: 		Build SHA1: 18ebb6cac8b6ed525da5713f42aa6740cdf538ed
01/10/2018 19:42:26: 		MPI distribution: Open MPI
01/10/2018 19:42:26: 		MPI version: 1.10.7
01/10/2018 19:42:26: -------------------------------------------------------------------
01/10/2018 19:42:26: -------------------------------------------------------------------
01/10/2018 19:42:26: GPU info:

01/10/2018 19:42:26: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
01/10/2018 19:42:26: -------------------------------------------------------------------

Configuration, Raw:

01/10/2018 19:42:26: precision = "float"
deviceId = $DeviceId$
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
ndlMacros = "$ConfigDir$/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
truncated = false
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "$RunDir$/models/Pre1/cntkSpeech"
    newModel  = "$RunDir$/models/Pre2/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
AddLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "$RunDir$/models/Pre2/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "$DataDir$/glob_0000.scp"
    ]
    labels = [
        mlfFile = "$DataDir$/glob_0000.mlf"
        labelMappingFile = "$DataDir$/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
replaceCriterionNode = [
    action = "edit"
    currModel = "$RunDir$/models/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.sequence.0"
    editPath  = "$ConfigDir$/replace_ce_with_sequence_criterion.mel"
]
sequenceTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        useMersenneTwisterRand=true      
        frameMode = false
        nbruttsineachrecurrentiter = 1
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "$DataDir$/glob_0000.scp"
        ]
        labels = [
            mlfFile = "$DataDir$/glob_0000.mlf"
            labelMappingFile = "$DataDir$/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "$DataDir$/model.overalltying"
            transpFile = "$DataDir$/model.transprob"
        ]
        lattices = [
            denlatTocFile = "$DataDir$/*.lats.toc"
        ]
    ]
]
currentDirectory=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
RunDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu
DataDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
OutputDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu
DeviceId=0
timestamping=true


Configuration After Variable Resolution:

01/10/2018 19:42:26: precision = "float"
deviceId = 0
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
ndlMacros = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
truncated = false
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]
AddLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
replaceCriterionNode = [
    action = "edit"
    currModel = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]
sequenceTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        useMersenneTwisterRand=true      
        frameMode = false
        nbruttsineachrecurrentiter = 1
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/*.lats.toc"
        ]
    ]
]
currentDirectory=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
RunDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu
DataDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
OutputDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu
DeviceId=0
timestamping=true


Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
configparameters: cntk_sequence.cntk:DataDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        useMersenneTwisterRand=true      
        frameMode = false
        nbruttsineachrecurrentiter = 1
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
01/10/2018 19:42:26: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
01/10/2018 19:42:26: precision = "float"

01/10/2018 19:42:26: ##############################################################################
01/10/2018 19:42:26: #                                                                            #
01/10/2018 19:42:26: # dptPre1 command (train action)                                             #
01/10/2018 19:42:26: #                                                                            #
01/10/2018 19:42:26: ##############################################################################

01/10/2018 19:42:26: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/10/2018 19:42:27: 
Model has 19 nodes. Using GPU 0.

01/10/2018 19:42:27: Training criterion:   ce = CrossEntropyWithSoftmax
01/10/2018 19:42:27: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 2 are aliased.
	OL.t (gradient) reuses OL.z (gradient)

Memory Sharing: Out of 29 matrices, 12 are shared as 3, and 17 are not shared.

Here are the ones that share memory:
	{ HL1.t : [512 x *]
	  HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *]
	  HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *]
	  OL.t : [132 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] }

Here are the ones that don't share memory:
	{scaledLogLikelihood : [132 x 1 x *]}
	{ce : [1]}
	{OL.b : [132 x 1] (gradient)}
	{ce : [1] (gradient)}
	{logPrior : [132 x 1]}
	{OL.W : [132 x 512] (gradient)}
	{err : [1]}
	{OL.W : [132 x 512]}
	{OL.b : [132 x 1]}
	{labels : [132 x *]}
	{globalMean : [363 x 1]}
	{globalInvStd : [363 x 1]}
	{globalPrior : [132 x 1]}
	{HL1.W : [512 x 363]}
	{HL1.b : [512 x 1]}
	{features : [363 x *]}
	{featNorm : [363 x *]}


01/10/2018 19:42:27: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

01/10/2018 19:42:27: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 19:42:27: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:27: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 19:42:27: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 19:42:27: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/10/2018 19:42:27: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 19:42:28: Starting minibatch loop.
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.74183807 * 2560; err = 0.80195313 * 2560; time = 0.2519s; samplesPerSecond = 10164.4
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.91124802 * 2560; err = 0.70898438 * 2560; time = 0.0619s; samplesPerSecond = 41387.0
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.58016052 * 2560; err = 0.66640625 * 2560; time = 0.0613s; samplesPerSecond = 41732.8
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.27427139 * 2560; err = 0.58750000 * 2560; time = 0.0613s; samplesPerSecond = 41777.2
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 2.05503540 * 2560; err = 0.56093750 * 2560; time = 0.0616s; samplesPerSecond = 41560.5
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.91055145 * 2560; err = 0.52812500 * 2560; time = 0.0628s; samplesPerSecond = 40776.4
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.81562805 * 2560; err = 0.51171875 * 2560; time = 0.0617s; samplesPerSecond = 41500.8
01/10/2018 19:42:28:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.68803253 * 2560; err = 0.48476562 * 2560; time = 0.0611s; samplesPerSecond = 41926.8
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.57382050 * 2560; err = 0.45429687 * 2560; time = 0.0615s; samplesPerSecond = 41619.8
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62090302 * 2560; err = 0.47304687 * 2560; time = 0.0618s; samplesPerSecond = 41422.7
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.59272614 * 2560; err = 0.47500000 * 2560; time = 0.0616s; samplesPerSecond = 41575.9
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.51520386 * 2560; err = 0.44531250 * 2560; time = 0.0609s; samplesPerSecond = 42039.0
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.49181824 * 2560; err = 0.45039062 * 2560; time = 0.0616s; samplesPerSecond = 41578.1
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53703613 * 2560; err = 0.44804688 * 2560; time = 0.0619s; samplesPerSecond = 41359.9
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.43095093 * 2560; err = 0.41640625 * 2560; time = 0.0612s; samplesPerSecond = 41813.7
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.41503601 * 2560; err = 0.40078125 * 2560; time = 0.0617s; samplesPerSecond = 41479.3
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.38912964 * 2560; err = 0.41132812 * 2560; time = 0.0625s; samplesPerSecond = 40929.4
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.41208496 * 2560; err = 0.42226562 * 2560; time = 0.0634s; samplesPerSecond = 40369.9
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.39965820 * 2560; err = 0.40664062 * 2560; time = 0.0615s; samplesPerSecond = 41605.0
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42728577 * 2560; err = 0.42617187 * 2560; time = 0.0622s; samplesPerSecond = 41140.2
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.41336060 * 2560; err = 0.42304687 * 2560; time = 0.0615s; samplesPerSecond = 41638.8
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.33195801 * 2560; err = 0.39960937 * 2560; time = 0.0626s; samplesPerSecond = 40914.7
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.28579712 * 2560; err = 0.38671875 * 2560; time = 0.0642s; samplesPerSecond = 39853.7
01/10/2018 19:42:29:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.34128113 * 2560; err = 0.40937500 * 2560; time = 0.0616s; samplesPerSecond = 41543.5
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.32663879 * 2560; err = 0.39648438 * 2560; time = 0.0760s; samplesPerSecond = 33694.1
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.21426086 * 2560; err = 0.37187500 * 2560; time = 0.0628s; samplesPerSecond = 40752.6
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23750000 * 2560; err = 0.37382813 * 2560; time = 0.0614s; samplesPerSecond = 41689.7
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.29968262 * 2560; err = 0.39062500 * 2560; time = 0.0615s; samplesPerSecond = 41595.4
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.21239929 * 2560; err = 0.37382813 * 2560; time = 0.0620s; samplesPerSecond = 41269.5
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20531006 * 2560; err = 0.36796875 * 2560; time = 0.0617s; samplesPerSecond = 41523.1
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23578796 * 2560; err = 0.37187500 * 2560; time = 0.0616s; samplesPerSecond = 41547.8
01/10/2018 19:42:30:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.25570068 * 2560; err = 0.37968750 * 2560; time = 0.0568s; samplesPerSecond = 45106.4
01/10/2018 19:42:30: Finished Epoch[ 1 of 2]: [Training] ce = 1.62944050 * 81920; err = 0.46015625 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.02314s
01/10/2018 19:42:30: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech.1'

01/10/2018 19:42:30: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/10/2018 19:42:30: Starting minibatch loop.
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.23324184 * 2560; err = 0.38164063 * 2560; time = 0.0630s; samplesPerSecond = 40655.3
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.20339603 * 2560; err = 0.37226562 * 2560; time = 0.0621s; samplesPerSecond = 41246.4
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.28589058 * 2560; err = 0.37773438 * 2560; time = 0.0613s; samplesPerSecond = 41749.1
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.23064728 * 2560; err = 0.37773438 * 2560; time = 0.0625s; samplesPerSecond = 40966.2
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.18116455 * 2560; err = 0.35585937 * 2560; time = 0.0621s; samplesPerSecond = 41194.6
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.28143578 * 2560; err = 0.37929687 * 2560; time = 0.0616s; samplesPerSecond = 41575.3
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.22316818 * 2560; err = 0.37226562 * 2560; time = 0.0715s; samplesPerSecond = 35820.8
01/10/2018 19:42:30:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17917328 * 2560; err = 0.36679688 * 2560; time = 0.0622s; samplesPerSecond = 41178.0
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.23667755 * 2560; err = 0.36210938 * 2560; time = 0.0617s; samplesPerSecond = 41483.4
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18298416 * 2560; err = 0.37382813 * 2560; time = 0.0627s; samplesPerSecond = 40831.3
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.20064545 * 2560; err = 0.36562500 * 2560; time = 0.0620s; samplesPerSecond = 41266.4
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18663025 * 2560; err = 0.35156250 * 2560; time = 0.0625s; samplesPerSecond = 40989.8
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16763000 * 2560; err = 0.35546875 * 2560; time = 0.0622s; samplesPerSecond = 41153.2
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.13098907 * 2560; err = 0.35039063 * 2560; time = 0.0622s; samplesPerSecond = 41186.4
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09752045 * 2560; err = 0.32265625 * 2560; time = 0.0615s; samplesPerSecond = 41616.7
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09747925 * 2560; err = 0.33710937 * 2560; time = 0.0621s; samplesPerSecond = 41228.4
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.19010925 * 2560; err = 0.35625000 * 2560; time = 0.0615s; samplesPerSecond = 41597.4
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.16201630 * 2560; err = 0.36015625 * 2560; time = 0.0615s; samplesPerSecond = 41657.6
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11661987 * 2560; err = 0.34375000 * 2560; time = 0.0610s; samplesPerSecond = 41976.5
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11697693 * 2560; err = 0.34765625 * 2560; time = 0.0614s; samplesPerSecond = 41698.5
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.09923859 * 2560; err = 0.33125000 * 2560; time = 0.0687s; samplesPerSecond = 37266.3
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.12601929 * 2560; err = 0.33789062 * 2560; time = 0.0671s; samplesPerSecond = 38145.7
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.14013977 * 2560; err = 0.35429688 * 2560; time = 0.0617s; samplesPerSecond = 41524.5
01/10/2018 19:42:31:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.29293518 * 2560; err = 0.38867188 * 2560; time = 0.0622s; samplesPerSecond = 41133.9
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.18086853 * 2560; err = 0.35898438 * 2560; time = 0.0615s; samplesPerSecond = 41657.2
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.14109802 * 2560; err = 0.36171875 * 2560; time = 0.0643s; samplesPerSecond = 39822.6
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.14666138 * 2560; err = 0.34492187 * 2560; time = 0.0663s; samplesPerSecond = 38628.3
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.15356140 * 2560; err = 0.35000000 * 2560; time = 0.0664s; samplesPerSecond = 38526.4
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.07240295 * 2560; err = 0.33867188 * 2560; time = 0.0644s; samplesPerSecond = 39745.7
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08450623 * 2560; err = 0.33007812 * 2560; time = 0.0678s; samplesPerSecond = 37772.8
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07801514 * 2560; err = 0.33164063 * 2560; time = 0.0630s; samplesPerSecond = 40622.7
01/10/2018 19:42:32:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06560974 * 2560; err = 0.33281250 * 2560; time = 0.0567s; samplesPerSecond = 45127.4
01/10/2018 19:42:32: Finished Epoch[ 2 of 2]: [Training] ce = 1.16517038 * 81920; err = 0.35534668 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.0344s
01/10/2018 19:42:32: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech'

01/10/2018 19:42:32: Action "train" complete.


01/10/2018 19:42:32: ##############################################################################
01/10/2018 19:42:32: #                                                                            #
01/10/2018 19:42:32: # addLayer2 command (edit action)                                            #
01/10/2018 19:42:32: #                                                                            #
01/10/2018 19:42:32: ##############################################################################


01/10/2018 19:42:32: Action "edit" complete.


01/10/2018 19:42:32: ##############################################################################
01/10/2018 19:42:32: #                                                                            #
01/10/2018 19:42:32: # dptPre2 command (train action)                                             #
01/10/2018 19:42:32: #                                                                            #
01/10/2018 19:42:32: ##############################################################################

01/10/2018 19:42:32: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/10/2018 19:42:32: 
Model has 24 nodes. Using GPU 0.

01/10/2018 19:42:32: Training criterion:   ce = CrossEntropyWithSoftmax
01/10/2018 19:42:32: Evaluation criterion: err = ClassificationError

01/10/2018 19:42:32: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

01/10/2018 19:42:32: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 19:42:32: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:32: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 19:42:32: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:32: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 19:42:32: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 19:42:32: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/10/2018 19:42:32: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 19:42:33: Starting minibatch loop.
01/10/2018 19:42:33:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 4.65436707 * 2560; err = 0.81132812 * 2560; time = 0.0804s; samplesPerSecond = 31853.4
01/10/2018 19:42:33:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.87611237 * 2560; err = 0.70664063 * 2560; time = 0.0784s; samplesPerSecond = 32660.6
01/10/2018 19:42:33:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.30106964 * 2560; err = 0.59882813 * 2560; time = 0.0798s; samplesPerSecond = 32074.8
01/10/2018 19:42:33:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.96660919 * 2560; err = 0.52539062 * 2560; time = 0.0875s; samplesPerSecond = 29263.6
01/10/2018 19:42:33:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.74655914 * 2560; err = 0.48398438 * 2560; time = 0.0742s; samplesPerSecond = 34504.1
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.62835999 * 2560; err = 0.46210937 * 2560; time = 0.0959s; samplesPerSecond = 26693.7
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57696533 * 2560; err = 0.45468750 * 2560; time = 0.0735s; samplesPerSecond = 34845.4
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.47685089 * 2560; err = 0.42695312 * 2560; time = 0.0742s; samplesPerSecond = 34501.5
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.39075470 * 2560; err = 0.40625000 * 2560; time = 0.0722s; samplesPerSecond = 35449.0
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41970062 * 2560; err = 0.42421875 * 2560; time = 0.0814s; samplesPerSecond = 31446.2
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41201630 * 2560; err = 0.43476562 * 2560; time = 0.0851s; samplesPerSecond = 30087.7
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.38169403 * 2560; err = 0.41562500 * 2560; time = 0.0740s; samplesPerSecond = 34591.4
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.34602051 * 2560; err = 0.41093750 * 2560; time = 0.0708s; samplesPerSecond = 36156.1
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.38628082 * 2560; err = 0.39843750 * 2560; time = 0.0777s; samplesPerSecond = 32929.4
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32571716 * 2560; err = 0.39023438 * 2560; time = 0.0732s; samplesPerSecond = 34995.5
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.31520691 * 2560; err = 0.39140625 * 2560; time = 0.0707s; samplesPerSecond = 36208.6
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.26128540 * 2560; err = 0.37539062 * 2560; time = 0.0697s; samplesPerSecond = 36714.5
01/10/2018 19:42:34:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.28179016 * 2560; err = 0.38593750 * 2560; time = 0.0708s; samplesPerSecond = 36163.9
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29704285 * 2560; err = 0.39062500 * 2560; time = 0.0923s; samplesPerSecond = 27725.6
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.28553772 * 2560; err = 0.39218750 * 2560; time = 0.1003s; samplesPerSecond = 25516.1
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.26621399 * 2560; err = 0.38828125 * 2560; time = 0.1001s; samplesPerSecond = 25564.6
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.21440430 * 2560; err = 0.36796875 * 2560; time = 0.0721s; samplesPerSecond = 35515.6
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.21631470 * 2560; err = 0.36992188 * 2560; time = 0.0763s; samplesPerSecond = 33555.9
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.24478760 * 2560; err = 0.37812500 * 2560; time = 0.0699s; samplesPerSecond = 36614.3
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22629700 * 2560; err = 0.37734375 * 2560; time = 0.0717s; samplesPerSecond = 35718.9
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.15057373 * 2560; err = 0.34765625 * 2560; time = 0.0710s; samplesPerSecond = 36072.0
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.16724548 * 2560; err = 0.35156250 * 2560; time = 0.0737s; samplesPerSecond = 34712.5
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.22637939 * 2560; err = 0.36601563 * 2560; time = 0.0701s; samplesPerSecond = 36512.0
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.16267090 * 2560; err = 0.35976562 * 2560; time = 0.0702s; samplesPerSecond = 36467.5
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.16969299 * 2560; err = 0.35820313 * 2560; time = 0.0709s; samplesPerSecond = 36116.7
01/10/2018 19:42:35:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.16425781 * 2560; err = 0.35195312 * 2560; time = 0.0701s; samplesPerSecond = 36498.2
01/10/2018 19:42:36:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.17123108 * 2560; err = 0.35234375 * 2560; time = 0.0726s; samplesPerSecond = 35268.8
01/10/2018 19:42:36: Finished Epoch[ 1 of 2]: [Training] ce = 1.52218781 * 81920; err = 0.42672119 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.27233s
01/10/2018 19:42:36: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.1'

01/10/2018 19:42:36: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/10/2018 19:42:36: Starting minibatch loop.
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.14802532 * 2560; err = 0.35117188 * 2560; time = 0.0712s; samplesPerSecond = 35948.3
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.17314568 * 2560; err = 0.36015625 * 2560; time = 0.0694s; samplesPerSecond = 36879.3
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.23122158 * 2560; err = 0.37265625 * 2560; time = 0.0681s; samplesPerSecond = 37577.0
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.17969055 * 2560; err = 0.35898438 * 2560; time = 0.0702s; samplesPerSecond = 36465.4
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.13304825 * 2560; err = 0.34843750 * 2560; time = 0.0674s; samplesPerSecond = 37969.7
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.22006378 * 2560; err = 0.36953125 * 2560; time = 0.0696s; samplesPerSecond = 36801.9
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14098816 * 2560; err = 0.34726563 * 2560; time = 0.0680s; samplesPerSecond = 37652.5
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.12340546 * 2560; err = 0.34921875 * 2560; time = 0.0677s; samplesPerSecond = 37835.1
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.14668121 * 2560; err = 0.33945313 * 2560; time = 0.0877s; samplesPerSecond = 29181.2
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12819672 * 2560; err = 0.34960938 * 2560; time = 0.0701s; samplesPerSecond = 36539.3
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14891510 * 2560; err = 0.34687500 * 2560; time = 0.0699s; samplesPerSecond = 36646.9
01/10/2018 19:42:36:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13158951 * 2560; err = 0.34296875 * 2560; time = 0.0702s; samplesPerSecond = 36443.3
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.11186981 * 2560; err = 0.33671875 * 2560; time = 0.0680s; samplesPerSecond = 37656.9
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.06695404 * 2560; err = 0.32382813 * 2560; time = 0.0679s; samplesPerSecond = 37700.2
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.05429382 * 2560; err = 0.30937500 * 2560; time = 0.0709s; samplesPerSecond = 36126.1
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.06546631 * 2560; err = 0.32851562 * 2560; time = 0.0680s; samplesPerSecond = 37653.0
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.13989563 * 2560; err = 0.34335938 * 2560; time = 0.0692s; samplesPerSecond = 37011.1
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13786621 * 2560; err = 0.35976562 * 2560; time = 0.0718s; samplesPerSecond = 35647.6
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.07601318 * 2560; err = 0.33125000 * 2560; time = 0.0681s; samplesPerSecond = 37578.9
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.06908112 * 2560; err = 0.33476563 * 2560; time = 0.0675s; samplesPerSecond = 37928.9
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.05689087 * 2560; err = 0.32656250 * 2560; time = 0.0706s; samplesPerSecond = 36256.7
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.08632202 * 2560; err = 0.32890625 * 2560; time = 0.0673s; samplesPerSecond = 38015.9
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.11229401 * 2560; err = 0.34375000 * 2560; time = 0.0674s; samplesPerSecond = 37964.8
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12421875 * 2560; err = 0.34960938 * 2560; time = 0.0684s; samplesPerSecond = 37446.7
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.08749695 * 2560; err = 0.33593750 * 2560; time = 0.0697s; samplesPerSecond = 36743.6
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.06223145 * 2560; err = 0.32812500 * 2560; time = 0.0676s; samplesPerSecond = 37854.4
01/10/2018 19:42:37:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.06559448 * 2560; err = 0.32500000 * 2560; time = 0.0713s; samplesPerSecond = 35914.9
01/10/2018 19:42:38:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.10242615 * 2560; err = 0.33007812 * 2560; time = 0.1056s; samplesPerSecond = 24239.8
01/10/2018 19:42:38:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.02162476 * 2560; err = 0.32539062 * 2560; time = 0.0971s; samplesPerSecond = 26361.4
01/10/2018 19:42:38:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.06609802 * 2560; err = 0.32617188 * 2560; time = 0.0762s; samplesPerSecond = 33598.1
01/10/2018 19:42:38:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.05944214 * 2560; err = 0.32304688 * 2560; time = 0.0683s; samplesPerSecond = 37508.0
01/10/2018 19:42:38:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.05012207 * 2560; err = 0.33242187 * 2560; time = 0.0627s; samplesPerSecond = 40854.4
01/10/2018 19:42:38: Finished Epoch[ 2 of 2]: [Training] ce = 1.11003666 * 81920; err = 0.33996582 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.31109s
01/10/2018 19:42:38: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech'

01/10/2018 19:42:38: Action "train" complete.


01/10/2018 19:42:38: ##############################################################################
01/10/2018 19:42:38: #                                                                            #
01/10/2018 19:42:38: # addLayer3 command (edit action)                                            #
01/10/2018 19:42:38: #                                                                            #
01/10/2018 19:42:38: ##############################################################################


01/10/2018 19:42:38: Action "edit" complete.


01/10/2018 19:42:38: ##############################################################################
01/10/2018 19:42:38: #                                                                            #
01/10/2018 19:42:38: # speechTrain command (train action)                                         #
01/10/2018 19:42:38: #                                                                            #
01/10/2018 19:42:38: ##############################################################################

01/10/2018 19:42:38: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/10/2018 19:42:38: 
Model has 29 nodes. Using GPU 0.

01/10/2018 19:42:38: Training criterion:   ce = CrossEntropyWithSoftmax
01/10/2018 19:42:38: Evaluation criterion: err = ClassificationError

01/10/2018 19:42:38: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

01/10/2018 19:42:38: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 19:42:38: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:38: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 19:42:38: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:38: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 19:42:38: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:38: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 19:42:38: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 19:42:38: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/10/2018 19:42:38: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 19:42:39: Starting minibatch loop.
01/10/2018 19:42:39:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 3.98617706 * 2560; err = 0.81132812 * 2560; time = 0.0843s; samplesPerSecond = 30353.4
01/10/2018 19:42:39:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.65327377 * 2560; err = 0.64609375 * 2560; time = 0.0799s; samplesPerSecond = 32037.4
01/10/2018 19:42:39:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.04344254 * 2560; err = 0.54882812 * 2560; time = 0.0790s; samplesPerSecond = 32391.9
01/10/2018 19:42:39:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.75020447 * 2560; err = 0.47851562 * 2560; time = 0.0915s; samplesPerSecond = 27986.4
01/10/2018 19:42:39:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.57851944 * 2560; err = 0.44960937 * 2560; time = 0.0956s; samplesPerSecond = 26773.6
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.47935410 * 2560; err = 0.42226562 * 2560; time = 0.0751s; samplesPerSecond = 34088.5
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.43710175 * 2560; err = 0.41054687 * 2560; time = 0.0757s; samplesPerSecond = 33815.2
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36245575 * 2560; err = 0.39609375 * 2560; time = 0.0908s; samplesPerSecond = 28201.3
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.27734070 * 2560; err = 0.37539062 * 2560; time = 0.0832s; samplesPerSecond = 30754.3
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30455475 * 2560; err = 0.39843750 * 2560; time = 0.0748s; samplesPerSecond = 34208.9
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.28724823 * 2560; err = 0.38984375 * 2560; time = 0.0740s; samplesPerSecond = 34581.2
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27779541 * 2560; err = 0.38398437 * 2560; time = 0.0765s; samplesPerSecond = 33458.5
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24093323 * 2560; err = 0.38359375 * 2560; time = 0.0750s; samplesPerSecond = 34119.5
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.31192780 * 2560; err = 0.38750000 * 2560; time = 0.0746s; samplesPerSecond = 34307.5
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.25088348 * 2560; err = 0.36796875 * 2560; time = 0.0749s; samplesPerSecond = 34195.5
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.26782379 * 2560; err = 0.38085938 * 2560; time = 0.0762s; samplesPerSecond = 33574.2
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.19906921 * 2560; err = 0.35820313 * 2560; time = 0.0775s; samplesPerSecond = 33051.4
01/10/2018 19:42:40:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20673828 * 2560; err = 0.36679688 * 2560; time = 0.0749s; samplesPerSecond = 34166.0
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21287537 * 2560; err = 0.36953125 * 2560; time = 0.0751s; samplesPerSecond = 34085.3
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.20243225 * 2560; err = 0.37617187 * 2560; time = 0.0740s; samplesPerSecond = 34603.5
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.20143738 * 2560; err = 0.37460938 * 2560; time = 0.0737s; samplesPerSecond = 34723.3
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.13604126 * 2560; err = 0.34414062 * 2560; time = 0.0721s; samplesPerSecond = 35515.1
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.14999695 * 2560; err = 0.34687500 * 2560; time = 0.0785s; samplesPerSecond = 32620.4
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.18746033 * 2560; err = 0.35703125 * 2560; time = 0.0977s; samplesPerSecond = 26210.9
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17141724 * 2560; err = 0.36210938 * 2560; time = 0.0717s; samplesPerSecond = 35726.8
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.08553772 * 2560; err = 0.33867188 * 2560; time = 0.0762s; samplesPerSecond = 33603.5
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.11324768 * 2560; err = 0.34335938 * 2560; time = 0.0728s; samplesPerSecond = 35145.6
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.17917480 * 2560; err = 0.35351562 * 2560; time = 0.0760s; samplesPerSecond = 33687.8
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.11235657 * 2560; err = 0.34375000 * 2560; time = 0.0749s; samplesPerSecond = 34177.1
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.13317871 * 2560; err = 0.34257813 * 2560; time = 0.0849s; samplesPerSecond = 30151.2
01/10/2018 19:42:41:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12384949 * 2560; err = 0.34062500 * 2560; time = 0.0754s; samplesPerSecond = 33937.8
01/10/2018 19:42:42:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12303772 * 2560; err = 0.34257813 * 2560; time = 0.0727s; samplesPerSecond = 35221.8
01/10/2018 19:42:42: Finished Epoch[ 1 of 4]: [Training] ce = 1.40771523 * 81920; err = 0.40285645 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.29854s
01/10/2018 19:42:42: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.1'

01/10/2018 19:42:42: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/10/2018 19:42:42: Starting minibatch loop.
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.50690136 * 5120; err = 0.41445312 * 5120; time = 0.1119s; samplesPerSecond = 45760.3
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.43394032 * 5120; err = 0.40312500 * 5120; time = 0.1083s; samplesPerSecond = 47285.2
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.19498672 * 5120; err = 0.36425781 * 5120; time = 0.1129s; samplesPerSecond = 45368.3
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.13462753 * 5120; err = 0.34609375 * 5120; time = 0.1144s; samplesPerSecond = 44757.3
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.12732811 * 5120; err = 0.34101562 * 5120; time = 0.1107s; samplesPerSecond = 46251.4
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.13973351 * 5120; err = 0.34941406 * 5120; time = 0.1141s; samplesPerSecond = 44865.0
01/10/2018 19:42:42:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.09274750 * 5120; err = 0.33613281 * 5120; time = 0.1140s; samplesPerSecond = 44930.7
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07956161 * 5120; err = 0.33359375 * 5120; time = 0.1143s; samplesPerSecond = 44791.0
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.14393692 * 5120; err = 0.35195312 * 5120; time = 0.1146s; samplesPerSecond = 44679.6
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06811905 * 5120; err = 0.33457031 * 5120; time = 0.1133s; samplesPerSecond = 45200.2
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.06341400 * 5120; err = 0.33496094 * 5120; time = 0.1144s; samplesPerSecond = 44763.2
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.12287140 * 5120; err = 0.35117188 * 5120; time = 0.1117s; samplesPerSecond = 45819.6
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.09922638 * 5120; err = 0.34550781 * 5120; time = 0.1137s; samplesPerSecond = 45035.5
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08422241 * 5120; err = 0.32832031 * 5120; time = 0.1134s; samplesPerSecond = 45145.6
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.03713837 * 5120; err = 0.32539062 * 5120; time = 0.1155s; samplesPerSecond = 44312.0
01/10/2018 19:42:43:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05823059 * 5120; err = 0.32636719 * 5120; time = 0.1027s; samplesPerSecond = 49860.7
01/10/2018 19:42:43: Finished Epoch[ 2 of 4]: [Training] ce = 1.14918661 * 81920; err = 0.34914551 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=1.82036s
01/10/2018 19:42:43: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.2'

01/10/2018 19:42:44: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

01/10/2018 19:42:44: Starting minibatch loop.
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.11066446 * 5120; err = 0.34218750 * 5120; time = 0.1129s; samplesPerSecond = 45360.6
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10631495 * 5120; err = 0.34511719 * 5120; time = 0.1132s; samplesPerSecond = 45249.4
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09502583 * 5120; err = 0.34394531 * 5120; time = 0.1109s; samplesPerSecond = 46162.0
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.14925079 * 5120; err = 0.34570312 * 5120; time = 0.1130s; samplesPerSecond = 45323.3
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.13400726 * 5120; err = 0.34199219 * 5120; time = 0.1098s; samplesPerSecond = 46643.8
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.07996712 * 5120; err = 0.33652344 * 5120; time = 0.1102s; samplesPerSecond = 46479.1
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.07324677 * 5120; err = 0.33085938 * 5120; time = 0.1097s; samplesPerSecond = 46661.4
01/10/2018 19:42:44:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06941147 * 5120; err = 0.33046875 * 5120; time = 0.1134s; samplesPerSecond = 45134.7
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.02541656 * 5120; err = 0.31171875 * 5120; time = 0.1322s; samplesPerSecond = 38715.6
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.04684372 * 5120; err = 0.31835938 * 5120; time = 0.1267s; samplesPerSecond = 40416.5
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05219879 * 5120; err = 0.33691406 * 5120; time = 0.1106s; samplesPerSecond = 46307.5
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07827148 * 5120; err = 0.33300781 * 5120; time = 0.1108s; samplesPerSecond = 46229.7
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05986786 * 5120; err = 0.32187500 * 5120; time = 0.1080s; samplesPerSecond = 47408.4
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02186890 * 5120; err = 0.31972656 * 5120; time = 0.1079s; samplesPerSecond = 47436.2
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04579926 * 5120; err = 0.32832031 * 5120; time = 0.1087s; samplesPerSecond = 47118.7
01/10/2018 19:42:45:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.02374115 * 5120; err = 0.32285156 * 5120; time = 0.0981s; samplesPerSecond = 52193.6
01/10/2018 19:42:45: Finished Epoch[ 3 of 4]: [Training] ce = 1.07324352 * 81920; err = 0.33184814 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=1.8154s
01/10/2018 19:42:45: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.3'

01/10/2018 19:42:45: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

01/10/2018 19:42:45: Starting minibatch loop.
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02762766 * 5120; err = 0.31425781 * 5120; time = 0.1093s; samplesPerSecond = 46844.6
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.04846405 * 4926; err = 0.32866423 * 4926; time = 0.3092s; samplesPerSecond = 15930.3
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.01424675 * 5120; err = 0.32382813 * 5120; time = 0.1088s; samplesPerSecond = 47073.1
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 0.99905319 * 5120; err = 0.31582031 * 5120; time = 0.1098s; samplesPerSecond = 46648.6
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 0.99530144 * 5120; err = 0.31191406 * 5120; time = 0.1075s; samplesPerSecond = 47605.9
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00318260 * 5120; err = 0.32304688 * 5120; time = 0.1080s; samplesPerSecond = 47387.7
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01893272 * 5120; err = 0.31933594 * 5120; time = 0.1102s; samplesPerSecond = 46461.5
01/10/2018 19:42:46:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 0.99314346 * 5120; err = 0.31054688 * 5120; time = 0.1105s; samplesPerSecond = 46316.2
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99949417 * 5120; err = 0.30625000 * 5120; time = 0.1108s; samplesPerSecond = 46201.6
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.99980240 * 5120; err = 0.31035156 * 5120; time = 0.1096s; samplesPerSecond = 46725.4
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.02506561 * 5120; err = 0.31738281 * 5120; time = 0.1093s; samplesPerSecond = 46843.9
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.03906784 * 5120; err = 0.32265625 * 5120; time = 0.1180s; samplesPerSecond = 43403.4
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.97148972 * 5120; err = 0.29550781 * 5120; time = 0.1082s; samplesPerSecond = 47329.6
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.97292023 * 5120; err = 0.30605469 * 5120; time = 0.1094s; samplesPerSecond = 46780.7
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.98358307 * 5120; err = 0.31269531 * 5120; time = 0.1099s; samplesPerSecond = 46589.5
01/10/2018 19:42:47:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.98013763 * 5120; err = 0.29785156 * 5120; time = 0.1021s; samplesPerSecond = 50125.3
01/10/2018 19:42:47: Finished Epoch[ 4 of 4]: [Training] ce = 1.00425825 * 81920; err = 0.31357422 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=1.97346s
01/10/2018 19:42:47: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech'

01/10/2018 19:42:47: Action "train" complete.


01/10/2018 19:42:47: ##############################################################################
01/10/2018 19:42:47: #                                                                            #
01/10/2018 19:42:47: # replaceCriterionNode command (edit action)                                 #
01/10/2018 19:42:47: #                                                                            #
01/10/2018 19:42:47: ##############################################################################


01/10/2018 19:42:48: Action "edit" complete.


01/10/2018 19:42:48: ##############################################################################
01/10/2018 19:42:48: #                                                                            #
01/10/2018 19:42:48: # sequenceTrain command (train action)                                       #
01/10/2018 19:42:48: #                                                                            #
01/10/2018 19:42:48: ##############################################################################

01/10/2018 19:42:48: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.overalltying', '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list', '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/TestData/CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
01/10/2018 19:42:48: 
Model has 29 nodes. Using GPU 0.

01/10/2018 19:42:48: Training criterion:   ce = SequenceWithSoftmax
01/10/2018 19:42:48: Evaluation criterion: err = ClassificationError

01/10/2018 19:42:48: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

01/10/2018 19:42:48: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/10/2018 19:42:48: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:48: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 19:42:48: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:48: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
01/10/2018 19:42:48: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
01/10/2018 19:42:48: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/10/2018 19:42:48: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/10/2018 19:42:48: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

01/10/2018 19:42:48: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/10/2018 19:43:08: Starting minibatch loop.
dengamma value 1.080253
dengamma value 1.067689
dengamma value 1.042180
dengamma value 1.067685
dengamma value 1.004541
dengamma value 1.044386
dengamma value 1.018485
dengamma value 1.032631
dengamma value 0.987644
dengamma value 1.044526
01/10/2018 19:43:17:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08165252 * 3030; err = 0.32607261 * 3030; time = 9.2502s; samplesPerSecond = 327.6
dengamma value 0.980365
dengamma value 1.028082
dengamma value 1.040285
dengamma value 1.075532
dengamma value 1.056252
dengamma value 1.009291
dengamma value 0.992798
dengamma value 0.978064
dengamma value 0.932198
dengamma value 1.106062
01/10/2018 19:43:18:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08724076 * 2720; err = 0.33786765 * 2720; time = 0.5312s; samplesPerSecond = 5120.9
dengamma value 1.035071
dengamma value 1.118101
dengamma value 1.006747
dengamma value 1.059017
dengamma value 1.055108
dengamma value 1.084545
dengamma value 0.991679
dengamma value 0.936845
dengamma value 1.039256
dengamma value 0.931289
01/10/2018 19:43:18:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.09104709 * 2460; err = 0.33252033 * 2460; time = 0.3554s; samplesPerSecond = 6922.2
dengamma value 1.040184
dengamma value 1.039055
dengamma value 1.014026
dengamma value 1.047612
dengamma value 1.040258
dengamma value 1.078214
dengamma value 1.032576
dengamma value 1.049796
dengamma value 1.093907
dengamma value 1.080579
01/10/2018 19:43:19:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08277559 * 3390; err = 0.27935103 * 3390; time = 0.5075s; samplesPerSecond = 6680.2
dengamma value 1.128539
dengamma value 1.048068
dengamma value 1.068421
dengamma value 1.072376
dengamma value 0.957788
dengamma value 1.091699
dengamma value 1.022257
dengamma value 1.058061
dengamma value 1.015575
dengamma value 1.039573
01/10/2018 19:43:19:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.06665615 * 2630; err = 0.32053232 * 2630; time = 0.4287s; samplesPerSecond = 6134.2
dengamma value 1.131341
dengamma value 1.041073
dengamma value 1.020529
dengamma value 1.054854
dengamma value 1.008863
dengamma value 1.080206
dengamma value 0.976591
dengamma value 1.030409
dengamma value 1.098612
dengamma value 1.016832
01/10/2018 19:43:20:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08293189 * 2640; err = 0.33484848 * 2640; time = 0.4239s; samplesPerSecond = 6227.4
dengamma value 1.040253
dengamma value 1.058311
dengamma value 1.003161
dengamma value 0.981714
dengamma value 0.977427
dengamma value 1.108835
dengamma value 1.092119
dengamma value 1.039246
dengamma value 1.048264
dengamma value 1.064121
01/10/2018 19:43:20:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08746001 * 3260; err = 0.31012270 * 3260; time = 0.5116s; samplesPerSecond = 6372.1
dengamma value 1.076959
dengamma value 1.051403
dengamma value 1.040205
dengamma value 1.064915
dengamma value 1.084535
dengamma value 1.090415
dengamma value 1.039212
dengamma value 1.002837
dengamma value 1.056707
dengamma value 1.078135
01/10/2018 19:43:21:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08503245 * 2890; err = 0.25951557 * 2890; time = 0.4283s; samplesPerSecond = 6748.4
dengamma value 1.016384
dengamma value 1.059581
dengamma value 0.967086
dengamma value 1.055628
dengamma value 1.094590
dengamma value 1.075466
dengamma value 1.096281
dengamma value 1.002656
dengamma value 0.983438
dengamma value 1.019420
01/10/2018 19:43:21:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08579920 * 2940; err = 0.33775510 * 2940; time = 0.4517s; samplesPerSecond = 6508.4
dengamma value 1.092800
dengamma value 1.038324
dengamma value 1.140757
dengamma value 1.046527
dengamma value 1.026186
dengamma value 1.083826
dengamma value 1.061735
dengamma value 1.055290
dengamma value 1.027016
dengamma value 1.108295
01/10/2018 19:43:22:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.07898309 * 2650; err = 0.27207547 * 2650; time = 0.4455s; samplesPerSecond = 5948.0
dengamma value 1.008507
dengamma value 1.028814
dengamma value 1.081874
dengamma value 1.021979
dengamma value 1.027849
dengamma value 1.113638
dengamma value 1.043323
dengamma value 1.067805
dengamma value 1.030856
dengamma value 0.981725
01/10/2018 19:43:22:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08667782 * 2410; err = 0.31784232 * 2410; time = 0.3739s; samplesPerSecond = 6446.3
dengamma value 1.046535
dengamma value 1.068982
dengamma value 1.052192
dengamma value 1.009178
dengamma value 1.048002
dengamma value 1.077289
dengamma value 1.061667
dengamma value 1.120863
dengamma value 1.010645
dengamma value 0.984418
01/10/2018 19:43:22:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.07902398 * 2700; err = 0.28370370 * 2700; time = 0.4212s; samplesPerSecond = 6410.9
dengamma value 0.998272
dengamma value 1.033722
dengamma value 1.037500
dengamma value 1.102122
dengamma value 1.074854
dengamma value 1.064235
dengamma value 1.072777
dengamma value 1.041915
dengamma value 1.056685
dengamma value 0.992420
01/10/2018 19:43:23:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08230493 * 2380; err = 0.31344538 * 2380; time = 0.3691s; samplesPerSecond = 6448.6
dengamma value 1.038496
dengamma value 0.939938
dengamma value 1.079450
dengamma value 0.943661
dengamma value 1.075549
dengamma value 1.044540
dengamma value 1.066575
dengamma value 1.097670
dengamma value 1.042503
dengamma value 0.966496
01/10/2018 19:43:23:  Epoch[ 1 of 3]-Minibatch[ 131- 140, 1.71%]: ce = 0.07805241 * 2630; err = 0.33650190 * 2630; time = 0.4368s; samplesPerSecond = 6021.7
dengamma value 1.018550
dengamma value 1.041486
dengamma value 1.046267
dengamma value 1.000197
dengamma value 1.090750
dengamma value 0.957786
dengamma value 1.065769
dengamma value 1.038824
dengamma value 1.116252
dengamma value 1.068008
01/10/2018 19:43:24:  Epoch[ 1 of 3]-Minibatch[ 141- 150, 1.83%]: ce = 0.08323313 * 3100; err = 0.30064516 * 3100; time = 0.5087s; samplesPerSecond = 6093.5
dengamma value 1.050971
dengamma value 0.915434
dengamma value 1.015281
dengamma value 0.991028
dengamma value 1.041436
dengamma value 1.046395
dengamma value 0.971504
dengamma value 0.971773
dengamma value 0.997714
dengamma value 1.042477
01/10/2018 19:43:24:  Epoch[ 1 of 3]-Minibatch[ 151- 160, 1.95%]: ce = 0.07853896 * 2720; err = 0.37389706 * 2720; time = 0.3960s; samplesPerSecond = 6868.6
dengamma value 1.132829
dengamma value 1.009499
dengamma value 1.022227
dengamma value 1.051635
dengamma value 1.018651
dengamma value 0.992456
dengamma value 1.025193
dengamma value 1.036403
dengamma value 1.053072
dengamma value 0.973979
01/10/2018 19:43:25:  Epoch[ 1 of 3]-Minibatch[ 161- 170, 2.08%]: ce = 0.08243001 * 3000; err = 0.32733333 * 3000; time = 0.4368s; samplesPerSecond = 6868.8
dengamma value 1.201442
dengamma value 1.093756
dengamma value 1.077422
dengamma value 1.109972
dengamma value 1.013516
dengamma value 1.068917
dengamma value 1.088443
dengamma value 1.033188
dengamma value 1.028257
dengamma value 1.005541
01/10/2018 19:43:25:  Epoch[ 1 of 3]-Minibatch[ 171- 180, 2.20%]: ce = 0.07515047 * 3370; err = 0.25756677 * 3370; time = 0.5110s; samplesPerSecond = 6594.4
dengamma value 1.071825
dengamma value 1.092703
dengamma value 1.065349
dengamma value 0.939167
dengamma value 1.063972
dengamma value 0.971679
dengamma value 1.067106
dengamma value 0.970956
dengamma value 1.061562
dengamma value 1.071068
01/10/2018 19:43:25:  Epoch[ 1 of 3]-Minibatch[ 181- 190, 2.32%]: ce = 0.08066143 * 2600; err = 0.36884615 * 2600; time = 0.4271s; samplesPerSecond = 6087.9
dengamma value 1.066920
dengamma value 1.102685
dengamma value 1.029546
dengamma value 1.013205
dengamma value 1.055307
dengamma value 0.998137
dengamma value 1.130044
dengamma value 0.964602
dengamma value 1.112891
dengamma value 0.987712
01/10/2018 19:43:26:  Epoch[ 1 of 3]-Minibatch[ 191- 200, 2.44%]: ce = 0.08197341 * 2600; err = 0.32346154 * 2600; time = 0.4151s; samplesPerSecond = 6263.9
dengamma value 1.065288
dengamma value 1.033971
dengamma value 0.950163
dengamma value 1.041062
dengamma value 1.062762
dengamma value 0.988958
dengamma value 1.009080
dengamma value 1.090582
dengamma value 1.108479
dengamma value 1.091485
01/10/2018 19:43:26:  Epoch[ 1 of 3]-Minibatch[ 201- 210, 2.56%]: ce = 0.07708135 * 2300; err = 0.32478261 * 2300; time = 0.3813s; samplesPerSecond = 6032.6
dengamma value 0.993733
dengamma value 1.004931
dengamma value 0.971299
dengamma value 1.049173
dengamma value 1.021343
dengamma value 1.037245
dengamma value 1.130205
dengamma value 1.016300
dengamma value 1.050008
dengamma value 1.030918
01/10/2018 19:43:27:  Epoch[ 1 of 3]-Minibatch[ 211- 220, 2.69%]: ce = 0.08699445 * 2800; err = 0.32857143 * 2800; time = 0.4394s; samplesPerSecond = 6371.9
dengamma value 1.039935
dengamma value 1.060128
dengamma value 1.080673
dengamma value 1.065894
dengamma value 0.983916
dengamma value 1.010557
dengamma value 1.034584
dengamma value 1.030356
dengamma value 1.079311
dengamma value 1.004008
01/10/2018 19:43:27:  Epoch[ 1 of 3]-Minibatch[ 221- 230, 2.81%]: ce = 0.08768155 * 2590; err = 0.32934363 * 2590; time = 0.4036s; samplesPerSecond = 6417.2
dengamma value 0.976138
dengamma value 1.043548
dengamma value 1.068995
dengamma value 1.046611
dengamma value 1.025841
dengamma value 1.061571
dengamma value 0.980198
dengamma value 1.120162
dengamma value 1.084923
dengamma value 1.074295
01/10/2018 19:43:27:  Epoch[ 1 of 3]-Minibatch[ 231- 240, 2.93%]: ce = 0.07955112 * 2610; err = 0.31954023 * 2610; time = 0.3978s; samplesPerSecond = 6560.4
dengamma value 1.087295
dengamma value 1.069230
dengamma value 1.060148
dengamma value 1.070807
dengamma value 1.059704
dengamma value 1.085482
dengamma value 1.081316
dengamma value 1.012590
dengamma value 1.041934
dengamma value 1.002299
01/10/2018 19:43:28:  Epoch[ 1 of 3]-Minibatch[ 241- 250, 3.05%]: ce = 0.08083700 * 2400; err = 0.31708333 * 2400; time = 0.3633s; samplesPerSecond = 6605.9
dengamma value 1.039996
dengamma value 1.044437
dengamma value 1.066881
dengamma value 1.058950
dengamma value 1.021345
dengamma value 1.022647
dengamma value 1.120009
dengamma value 1.063299
dengamma value 1.042732
dengamma value 1.001401
01/10/2018 19:43:28:  Epoch[ 1 of 3]-Minibatch[ 251- 260, 3.17%]: ce = 0.08029221 * 3200; err = 0.29812500 * 3200; time = 0.5014s; samplesPerSecond = 6381.6
dengamma value 1.082492
dengamma value 1.029519
dengamma value 1.090167
dengamma value 1.015034
dengamma value 1.067875
dengamma value 1.013305
dengamma value 1.072346
dengamma value 1.028794
dengamma value 1.058543
dengamma value 0.999644
01/10/2018 19:43:29:  Epoch[ 1 of 3]-Minibatch[ 261- 270, 3.30%]: ce = 0.08882793 * 3570; err = 0.30728291 * 3570; time = 0.5850s; samplesPerSecond = 6102.8
dengamma value 0.998150
dengamma value 1.055285
dengamma value 1.064699
dengamma value 0.996475
dengamma value 1.042647
dengamma value 0.989538
dengamma value 1.021472
dengamma value 1.111220
dengamma value 0.964095
dengamma value 1.036054
01/10/2018 19:43:29:  Epoch[ 1 of 3]-Minibatch[ 271- 280, 3.42%]: ce = 0.09733138 * 2510; err = 0.36135458 * 2510; time = 0.3752s; samplesPerSecond = 6690.1
dengamma value 0.987407
dengamma value 1.091151
dengamma value 0.904078
dengamma value 1.056926
dengamma value 1.063885
dengamma value 1.074718
dengamma value 1.071570
dengamma value 1.026333
dengamma value 1.051824
dengamma value 1.051871
01/10/2018 19:43:30:  Epoch[ 1 of 3]-Minibatch[ 281- 290, 3.54%]: ce = 0.07619658 * 3400; err = 0.36764706 * 3400; time = 0.5204s; samplesPerSecond = 6533.0
dengamma value 1.102554
dengamma value 1.043310
dengamma value 0.997795
01/10/2018 19:43:30: Finished Epoch[ 1 of 3]: [Training] ce = 0.08243962 * 82104; err = 0.31908311 * 82104; totalSamplesSeen = 82104; learningRatePerSample = 2e-06; epochTime=41.8213s
01/10/2018 19:43:30: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.1'

01/10/2018 19:43:30: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82104), data subset 0 of 1, with 1 datapasses

01/10/2018 19:43:30: Starting minibatch loop.
dengamma value 1.052655
dengamma value 1.057056
dengamma value 1.025690
dengamma value 0.928939
dengamma value 1.095931
dengamma value 1.027296
dengamma value 1.046845
dengamma value 1.035925
dengamma value 1.037084
dengamma value 1.021232
01/10/2018 19:43:30:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08635419 * 2880; err = 0.30729167 * 2880; time = 0.4260s; samplesPerSecond = 6760.0
dengamma value 1.025705
dengamma value 1.113063
dengamma value 1.029926
dengamma value 1.004404
dengamma value 1.056410
dengamma value 1.035267
dengamma value 1.032557
dengamma value 1.051168
dengamma value 1.042503
dengamma value 1.095508
01/10/2018 19:43:31:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08077003 * 2560; err = 0.29375000 * 2560; time = 0.4054s; samplesPerSecond = 6314.2
dengamma value 1.050676
dengamma value 1.043484
dengamma value 1.028195
dengamma value 1.128741
dengamma value 1.003429
dengamma value 1.030360
dengamma value 0.983549
dengamma value 1.002505
dengamma value 1.057276
dengamma value 1.030917
01/10/2018 19:43:31:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08661261 * 2240; err = 0.33348214 * 2240; time = 0.3569s; samplesPerSecond = 6276.0
dengamma value 1.038815
dengamma value 1.002405
dengamma value 1.072729
dengamma value 1.061703
dengamma value 1.003557
dengamma value 1.000736
dengamma value 1.004716
dengamma value 1.057324
dengamma value 1.010985
dengamma value 1.042629
01/10/2018 19:43:32:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08876555 * 2940; err = 0.32687075 * 2940; time = 0.4670s; samplesPerSecond = 6296.0
dengamma value 1.053948
dengamma value 1.032590
dengamma value 1.063952
dengamma value 1.029132
dengamma value 1.072877
dengamma value 1.033262
dengamma value 1.040993
dengamma value 1.041870
dengamma value 1.012890
dengamma value 1.051658
01/10/2018 19:43:32:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08337694 * 2570; err = 0.30856031 * 2570; time = 0.3700s; samplesPerSecond = 6945.3
dengamma value 0.994512
dengamma value 1.016723
dengamma value 1.088349
dengamma value 1.038862
dengamma value 1.067400
dengamma value 1.027572
dengamma value 0.999487
dengamma value 1.048089
dengamma value 1.025518
dengamma value 1.019460
01/10/2018 19:43:32:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08775556 * 2800; err = 0.29142857 * 2800; time = 0.4064s; samplesPerSecond = 6889.1
dengamma value 1.000464
dengamma value 1.018787
dengamma value 1.011880
dengamma value 1.065424
dengamma value 0.991735
dengamma value 1.090512
dengamma value 1.110843
dengamma value 1.032215
dengamma value 1.100741
dengamma value 1.097314
01/10/2018 19:43:33:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08067411 * 2540; err = 0.27716535 * 2540; time = 0.4261s; samplesPerSecond = 5960.9
dengamma value 1.023328
dengamma value 1.051840
dengamma value 1.058584
dengamma value 0.984557
dengamma value 0.993764
dengamma value 1.056291
dengamma value 0.991309
dengamma value 0.975028
dengamma value 1.003994
dengamma value 1.066583
01/10/2018 19:43:33:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08465341 * 2180; err = 0.34908257 * 2180; time = 0.3224s; samplesPerSecond = 6761.4
dengamma value 1.015943
dengamma value 1.010568
dengamma value 0.976458
dengamma value 0.966551
dengamma value 1.066943
dengamma value 1.107769
dengamma value 1.045684
dengamma value 1.075820
dengamma value 1.042910
dengamma value 0.996306
01/10/2018 19:43:34:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.09176460 * 3060; err = 0.34346405 * 3060; time = 0.4687s; samplesPerSecond = 6529.3
dengamma value 1.051210
dengamma value 1.088399
dengamma value 1.066022
dengamma value 1.020727
dengamma value 1.116520
dengamma value 1.060581
dengamma value 1.018369
dengamma value 0.991648
dengamma value 0.914790
dengamma value 0.994820
01/10/2018 19:43:34:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08300338 * 3280; err = 0.33018293 * 3280; time = 0.5135s; samplesPerSecond = 6387.7
dengamma value 1.040700
dengamma value 0.998121
dengamma value 1.099100
dengamma value 1.019290
dengamma value 0.999900
dengamma value 0.980724
dengamma value 1.044020
dengamma value 1.050316
dengamma value 1.049982
dengamma value 1.004874
01/10/2018 19:43:35:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.09032815 * 3270; err = 0.30672783 * 3270; time = 0.5076s; samplesPerSecond = 6442.6
dengamma value 1.062819
dengamma value 0.988548
dengamma value 1.037988
dengamma value 1.028741
dengamma value 1.091999
dengamma value 1.062228
dengamma value 1.018381
dengamma value 1.079168
dengamma value 1.101602
dengamma value 1.060160
01/10/2018 19:43:35:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08911200 * 2560; err = 0.30742188 * 2560; time = 0.4330s; samplesPerSecond = 5912.1
dengamma value 1.022661
dengamma value 1.048230
dengamma value 1.035977
dengamma value 1.025734
dengamma value 1.073334
dengamma value 1.012104
dengamma value 1.085388
dengamma value 1.043789
dengamma value 1.019012
dengamma value 1.048380
01/10/2018 19:43:36:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08057757 * 2820; err = 0.31276596 * 2820; time = 0.4312s; samplesPerSecond = 6539.8
dengamma value 1.013617
dengamma value 1.015770
dengamma value 1.045334
dengamma value 1.000870
dengamma value 1.126548
dengamma value 1.015717
dengamma value 1.033457
dengamma value 0.996100
dengamma value 1.036724
dengamma value 1.024622
01/10/2018 19:43:36:  Epoch[ 2 of 3]-Minibatch[ 131- 140, 1.71%]: ce = 0.08842925 * 2420; err = 0.36983471 * 2420; time = 0.3804s; samplesPerSecond = 6361.0
dengamma value 1.020505
dengamma value 1.036185
dengamma value 1.006404
dengamma value 1.044693
dengamma value 1.060347
dengamma value 1.055400
dengamma value 1.008021
dengamma value 1.043716
dengamma value 1.055703
dengamma value 1.003478
01/10/2018 19:43:36:  Epoch[ 2 of 3]-Minibatch[ 141- 150, 1.83%]: ce = 0.08026841 * 2040; err = 0.34411765 * 2040; time = 0.3366s; samplesPerSecond = 6060.8
dengamma value 1.033664
dengamma value 1.049960
dengamma value 1.044343
dengamma value 1.073125
dengamma value 1.056469
dengamma value 0.991933
dengamma value 1.107298
dengamma value 0.999532
dengamma value 0.948379
dengamma value 1.074967
01/10/2018 19:43:37:  Epoch[ 2 of 3]-Minibatch[ 151- 160, 1.95%]: ce = 0.08573743 * 3130; err = 0.33865815 * 3130; time = 0.4705s; samplesPerSecond = 6652.2
dengamma value 1.052257
dengamma value 1.093610
dengamma value 1.069263
dengamma value 1.059575
dengamma value 1.010945
dengamma value 1.067519
dengamma value 0.999180
dengamma value 1.050820
dengamma value 0.973597
dengamma value 1.040256
01/10/2018 19:43:37:  Epoch[ 2 of 3]-Minibatch[ 161- 170, 2.08%]: ce = 0.08825393 * 2600; err = 0.34192308 * 2600; time = 0.4300s; samplesPerSecond = 6046.0
dengamma value 1.040606
dengamma value 0.997177
dengamma value 1.073667
dengamma value 0.961624
dengamma value 1.014811
dengamma value 1.006879
dengamma value 0.955989
dengamma value 1.019185
dengamma value 1.063108
dengamma value 1.007653
01/10/2018 19:43:38:  Epoch[ 2 of 3]-Minibatch[ 171- 180, 2.20%]: ce = 0.09320360 * 2340; err = 0.36196581 * 2340; time = 0.3680s; samplesPerSecond = 6359.0
dengamma value 1.074573
dengamma value 1.099598
dengamma value 1.063231
dengamma value 1.056997
dengamma value 1.039119
dengamma value 0.988877
dengamma value 1.015738
dengamma value 1.036598
dengamma value 1.064753
dengamma value 0.877117
01/10/2018 19:43:38:  Epoch[ 2 of 3]-Minibatch[ 181- 190, 2.32%]: ce = 0.08793587 * 2590; err = 0.34440154 * 2590; time = 0.3871s; samplesPerSecond = 6690.3
dengamma value 1.139199
dengamma value 1.080550
dengamma value 0.968721
dengamma value 1.038054
dengamma value 0.995359
dengamma value 1.002190
dengamma value 1.034106
dengamma value 1.041023
dengamma value 1.038729
dengamma value 1.080178
01/10/2018 19:43:38:  Epoch[ 2 of 3]-Minibatch[ 191- 200, 2.44%]: ce = 0.09079294 * 2640; err = 0.30833333 * 2640; time = 0.4217s; samplesPerSecond = 6259.7
dengamma value 1.087167
dengamma value 1.112866
dengamma value 0.996264
dengamma value 1.081338
dengamma value 1.009663
dengamma value 1.087691
dengamma value 1.013028
dengamma value 1.097362
dengamma value 1.068617
dengamma value 1.040340
01/10/2018 19:43:39:  Epoch[ 2 of 3]-Minibatch[ 201- 210, 2.56%]: ce = 0.08913454 * 2840; err = 0.29330986 * 2840; time = 0.4360s; samplesPerSecond = 6513.6
dengamma value 1.030859
dengamma value 0.990938
dengamma value 0.997727
dengamma value 1.055816
dengamma value 0.990210
dengamma value 1.054213
dengamma value 1.098941
dengamma value 0.944434
dengamma value 1.015729
dengamma value 1.057585
01/10/2018 19:43:39:  Epoch[ 2 of 3]-Minibatch[ 211- 220, 2.69%]: ce = 0.08613859 * 2450; err = 0.36408163 * 2450; time = 0.3856s; samplesPerSecond = 6353.3
dengamma value 1.111145
dengamma value 1.036209
dengamma value 1.055468
dengamma value 1.030628
dengamma value 1.112278
dengamma value 1.096054
dengamma value 1.056210
dengamma value 1.035174
dengamma value 1.063409
dengamma value 1.011630
01/10/2018 19:43:40:  Epoch[ 2 of 3]-Minibatch[ 221- 230, 2.81%]: ce = 0.08953451 * 3180; err = 0.30188679 * 3180; time = 0.4810s; samplesPerSecond = 6610.9
dengamma value 0.960249
dengamma value 1.099128
dengamma value 1.022825
dengamma value 1.032751
dengamma value 1.003689
dengamma value 1.060813
dengamma value 0.991986
dengamma value 1.069820
dengamma value 0.972319
dengamma value 1.052449
01/10/2018 19:43:40:  Epoch[ 2 of 3]-Minibatch[ 231- 240, 2.93%]: ce = 0.08495436 * 2970; err = 0.34107744 * 2970; time = 0.4978s; samplesPerSecond = 5965.9
dengamma value 1.042924
dengamma value 1.026052
dengamma value 1.077293
dengamma value 1.080837
dengamma value 1.041215
dengamma value 1.019982
dengamma value 1.025124
dengamma value 0.999494
dengamma value 1.005499
dengamma value 1.063635
01/10/2018 19:43:41:  Epoch[ 2 of 3]-Minibatch[ 241- 250, 3.05%]: ce = 0.08871466 * 2830; err = 0.28939929 * 2830; time = 0.4397s; samplesPerSecond = 6436.5
dengamma value 1.011111
dengamma value 1.069536
dengamma value 1.093582
dengamma value 1.005178
dengamma value 1.090356
dengamma value 0.956708
dengamma value 1.024993
dengamma value 1.004022
dengamma value 1.025747
dengamma value 1.074657
01/10/2018 19:43:41:  Epoch[ 2 of 3]-Minibatch[ 251- 260, 3.17%]: ce = 0.08225717 * 2600; err = 0.32961538 * 2600; time = 0.3808s; samplesPerSecond = 6826.9
dengamma value 1.100264
dengamma value 1.032646
dengamma value 1.093957
dengamma value 1.063794
dengamma value 1.064357
dengamma value 1.096832
dengamma value 1.052689
dengamma value 1.077232
dengamma value 1.121317
dengamma value 1.096178
01/10/2018 19:43:41:  Epoch[ 2 of 3]-Minibatch[ 261- 270, 3.30%]: ce = 0.07774090 * 2770; err = 0.26606498 * 2770; time = 0.4530s; samplesPerSecond = 6114.3
dengamma value 1.038584
dengamma value 1.018443
dengamma value 1.095015
dengamma value 1.008431
dengamma value 1.105742
dengamma value 1.082618
dengamma value 1.163381
dengamma value 1.027877
dengamma value 1.089569
dengamma value 1.087613
01/10/2018 19:43:42:  Epoch[ 2 of 3]-Minibatch[ 271- 280, 3.42%]: ce = 0.07785555 * 2450; err = 0.33265306 * 2450; time = 0.4176s; samplesPerSecond = 5866.5
dengamma value 0.961763
dengamma value 0.992846
dengamma value 1.080743
dengamma value 1.084199
dengamma value 1.058683
dengamma value 1.023934
dengamma value 1.053691
dengamma value 1.045325
dengamma value 1.059317
dengamma value 1.101472
01/10/2018 19:43:42:  Epoch[ 2 of 3]-Minibatch[ 281- 290, 3.54%]: ce = 0.08230186 * 2730; err = 0.33956044 * 2730; time = 0.4146s; samplesPerSecond = 6584.7
dengamma value 1.076159
dengamma value 0.998466
dengamma value 1.022811
dengamma value 0.962618
dengamma value 1.006305
dengamma value 1.002935
dengamma value 1.009188
dengamma value 1.035387
dengamma value 1.067099
dengamma value 1.012220
01/10/2018 19:43:43:  Epoch[ 2 of 3]-Minibatch[ 291- 300, 3.66%]: ce = 0.09049573 * 2440; err = 0.34098361 * 2440; time = 0.3834s; samplesPerSecond = 6364.6
dengamma value 1.049099
dengamma value 1.030162
dengamma value 0.968526
dengamma value 1.063861
01/10/2018 19:43:43: Finished Epoch[ 2 of 3]: [Training] ce = 0.08601337 * 81852; err = 0.32236231 * 81852; totalSamplesSeen = 163956; learningRatePerSample = 2e-06; epochTime=12.7887s
01/10/2018 19:43:43: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.2'

01/10/2018 19:43:43: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163956), data subset 0 of 1, with 1 datapasses

01/10/2018 19:43:43: Starting minibatch loop.
dengamma value 1.111798
dengamma value 1.030438
dengamma value 0.910685
dengamma value 1.018963
dengamma value 1.020927
dengamma value 1.026058
dengamma value 1.045831
dengamma value 1.036265
dengamma value 1.066696
dengamma value 0.959506
01/10/2018 19:43:43:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08999078 * 2810; err = 0.32419929 * 2810; time = 0.4142s; samplesPerSecond = 6784.3
dengamma value 1.030414
dengamma value 1.121382
dengamma value 1.085895
dengamma value 1.070674
dengamma value 1.066806
dengamma value 1.025559
dengamma value 1.164348
dengamma value 1.113479
dengamma value 1.081863
dengamma value 1.013224
01/10/2018 19:43:44:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08030723 * 1970; err = 0.31675127 * 1970; time = 0.3181s; samplesPerSecond = 6192.5
dengamma value 1.065215
dengamma value 1.042477
dengamma value 1.023545
dengamma value 0.997900
dengamma value 1.075859
dengamma value 1.053645
dengamma value 1.034658
dengamma value 1.038254
dengamma value 0.994656
dengamma value 1.063948
01/10/2018 19:43:44:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08681615 * 3050; err = 0.30491803 * 3050; time = 0.4515s; samplesPerSecond = 6755.2
dengamma value 1.005586
dengamma value 1.053669
dengamma value 1.055822
dengamma value 0.988433
dengamma value 1.133038
dengamma value 0.991717
dengamma value 0.995462
dengamma value 1.048374
dengamma value 1.077665
dengamma value 1.021016
01/10/2018 19:43:44:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.09237482 * 2230; err = 0.33766816 * 2230; time = 0.3647s; samplesPerSecond = 6114.9
dengamma value 1.016884
dengamma value 1.050618
dengamma value 1.017833
dengamma value 1.020923
dengamma value 1.096649
dengamma value 1.055808
dengamma value 1.033335
dengamma value 1.027184
dengamma value 0.987046
dengamma value 1.046492
01/10/2018 19:43:45:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08967792 * 2350; err = 0.33276596 * 2350; time = 0.3777s; samplesPerSecond = 6222.5
dengamma value 1.087668
dengamma value 0.972356
dengamma value 1.053939
dengamma value 1.043525
dengamma value 1.046437
dengamma value 1.064644
dengamma value 1.060721
dengamma value 1.084786
dengamma value 1.010506
dengamma value 0.967859
01/10/2018 19:43:45:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08764490 * 2850; err = 0.32701754 * 2850; time = 0.4377s; samplesPerSecond = 6511.8
dengamma value 0.988341
dengamma value 1.070573
dengamma value 1.067542
dengamma value 1.079431
dengamma value 1.026375
dengamma value 1.071602
dengamma value 1.092593
dengamma value 1.091836
dengamma value 1.032197
dengamma value 1.120227
01/10/2018 19:43:46:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07872686 * 3020; err = 0.29635762 * 3020; time = 0.5250s; samplesPerSecond = 5752.3
dengamma value 1.067589
dengamma value 0.964888
dengamma value 1.062751
dengamma value 1.083215
dengamma value 0.940903
dengamma value 1.018269
dengamma value 1.029190
dengamma value 1.005345
dengamma value 1.045982
dengamma value 1.004526
01/10/2018 19:43:46:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.09570719 * 2220; err = 0.31621622 * 2220; time = 0.3308s; samplesPerSecond = 6710.8
dengamma value 1.024425
dengamma value 1.010062
dengamma value 1.101464
dengamma value 1.126072
dengamma value 1.094763
dengamma value 1.025537
dengamma value 1.048396
dengamma value 1.119983
dengamma value 1.037519
dengamma value 1.038412
01/10/2018 19:43:47:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08718662 * 3110; err = 0.27266881 * 3110; time = 0.5415s; samplesPerSecond = 5743.0
dengamma value 1.009163
dengamma value 0.971466
dengamma value 1.009405
dengamma value 1.014007
dengamma value 1.024706
dengamma value 1.079028
dengamma value 0.989310
dengamma value 1.039213
dengamma value 1.106639
dengamma value 0.999306
01/10/2018 19:43:47:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08137245 * 2560; err = 0.36171875 * 2560; time = 0.4128s; samplesPerSecond = 6201.7
dengamma value 1.008572
dengamma value 1.062617
dengamma value 1.139191
dengamma value 1.113487
dengamma value 1.067832
dengamma value 1.052549
dengamma value 1.063481
dengamma value 1.042661
dengamma value 1.076476
dengamma value 1.000508
01/10/2018 19:43:47:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08208526 * 2780; err = 0.31834532 * 2780; time = 0.4201s; samplesPerSecond = 6617.7
dengamma value 1.021270
dengamma value 1.092370
dengamma value 1.094965
dengamma value 0.947553
dengamma value 0.974226
dengamma value 1.071490
dengamma value 1.042027
dengamma value 1.018933
dengamma value 1.080754
dengamma value 1.042438
01/10/2018 19:43:48:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.09031343 * 2520; err = 0.31984127 * 2520; time = 0.4183s; samplesPerSecond = 6025.1
dengamma value 1.046403
dengamma value 1.007634
dengamma value 0.951146
dengamma value 1.093432
dengamma value 1.126997
dengamma value 1.009498
dengamma value 1.028756
dengamma value 1.084926
dengamma value 1.087726
dengamma value 1.033391
01/10/2018 19:43:48:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08678168 * 2580; err = 0.32945736 * 2580; time = 0.3872s; samplesPerSecond = 6663.3
dengamma value 1.036427
dengamma value 1.035172
dengamma value 1.006061
dengamma value 1.065851
dengamma value 1.031004
dengamma value 1.089049
dengamma value 1.103049
dengamma value 0.971658
dengamma value 1.052040
dengamma value 0.960310
01/10/2018 19:43:49:  Epoch[ 3 of 3]-Minibatch[ 131- 140, 1.71%]: ce = 0.08291085 * 2450; err = 0.32816327 * 2450; time = 0.3495s; samplesPerSecond = 7010.3
dengamma value 0.962006
dengamma value 1.019025
dengamma value 1.031487
dengamma value 1.100423
dengamma value 0.995272
dengamma value 1.035665
dengamma value 1.100080
dengamma value 0.989436
dengamma value 1.048213
dengamma value 1.056372
01/10/2018 19:43:49:  Epoch[ 3 of 3]-Minibatch[ 141- 150, 1.83%]: ce = 0.08416284 * 2290; err = 0.32707424 * 2290; time = 0.3315s; samplesPerSecond = 6908.6
dengamma value 1.206052
dengamma value 1.031823
dengamma value 0.978875
dengamma value 1.052794
dengamma value 1.088127
dengamma value 1.044858
dengamma value 1.002532
dengamma value 1.034994
dengamma value 1.101144
dengamma value 1.064532
01/10/2018 19:43:49:  Epoch[ 3 of 3]-Minibatch[ 151- 160, 1.95%]: ce = 0.08205314 * 3000; err = 0.28833333 * 3000; time = 0.4419s; samplesPerSecond = 6788.8
dengamma value 1.212902
dengamma value 1.070188
dengamma value 1.055068
dengamma value 1.052456
dengamma value 0.942072
dengamma value 1.057915
dengamma value 1.074378
dengamma value 1.051175
dengamma value 0.967616
dengamma value 1.084036
01/10/2018 19:43:50:  Epoch[ 3 of 3]-Minibatch[ 161- 170, 2.08%]: ce = 0.07493940 * 2510; err = 0.32151394 * 2510; time = 0.3550s; samplesPerSecond = 7070.7
dengamma value 0.982366
dengamma value 1.064664
dengamma value 0.990646
dengamma value 1.053306
dengamma value 1.067497
dengamma value 1.061080
dengamma value 1.010541
dengamma value 1.092285
dengamma value 1.085366
dengamma value 1.058809
01/10/2018 19:43:50:  Epoch[ 3 of 3]-Minibatch[ 171- 180, 2.20%]: ce = 0.08661006 * 2610; err = 0.28812261 * 2610; time = 0.4215s; samplesPerSecond = 6192.5
dengamma value 1.082161
dengamma value 1.086701
dengamma value 1.073184
dengamma value 1.084952
dengamma value 0.988855
dengamma value 1.094023
dengamma value 1.020601
dengamma value 1.061420
dengamma value 1.057047
dengamma value 1.064171
01/10/2018 19:43:51:  Epoch[ 3 of 3]-Minibatch[ 181- 190, 2.32%]: ce = 0.08744700 * 2400; err = 0.32416667 * 2400; time = 0.3911s; samplesPerSecond = 6137.3
dengamma value 1.117552
dengamma value 1.078768
dengamma value 1.046778
dengamma value 1.056163
dengamma value 1.046923
dengamma value 1.029252
dengamma value 1.069630
dengamma value 1.060418
dengamma value 1.018464
dengamma value 1.046542
01/10/2018 19:43:51:  Epoch[ 3 of 3]-Minibatch[ 191- 200, 2.44%]: ce = 0.08645727 * 2590; err = 0.26640927 * 2590; time = 0.4188s; samplesPerSecond = 6184.9
dengamma value 1.110082
dengamma value 1.013135
dengamma value 1.067764
dengamma value 1.000595
dengamma value 1.064817
dengamma value 1.043320
dengamma value 1.064502
dengamma value 1.055064
dengamma value 0.984315
dengamma value 1.047622
01/10/2018 19:43:51:  Epoch[ 3 of 3]-Minibatch[ 201- 210, 2.56%]: ce = 0.07576140 * 2460; err = 0.38658537 * 2460; time = 0.4118s; samplesPerSecond = 5974.3
dengamma value 1.032113
dengamma value 1.091279
dengamma value 1.006342
dengamma value 1.053851
dengamma value 1.078657
dengamma value 0.995476
dengamma value 1.032127
dengamma value 1.050487
dengamma value 1.012389
dengamma value 1.030252
01/10/2018 19:43:52:  Epoch[ 3 of 3]-Minibatch[ 211- 220, 2.69%]: ce = 0.08107224 * 2810; err = 0.33807829 * 2810; time = 0.4070s; samplesPerSecond = 6904.0
dengamma value 1.037432
dengamma value 1.026661
dengamma value 1.051322
dengamma value 1.041616
dengamma value 1.059190
dengamma value 1.125505
dengamma value 1.139021
dengamma value 1.007017
dengamma value 0.993294
dengamma value 0.997127
01/10/2018 19:43:52:  Epoch[ 3 of 3]-Minibatch[ 221- 230, 2.81%]: ce = 0.08886374 * 2550; err = 0.32078431 * 2550; time = 0.3717s; samplesPerSecond = 6859.5
dengamma value 1.057820
dengamma value 1.041194
dengamma value 1.012787
dengamma value 1.021561
dengamma value 1.042943
dengamma value 1.039452
dengamma value 0.969742
dengamma value 0.988127
dengamma value 1.045247
dengamma value 1.041911
01/10/2018 19:43:53:  Epoch[ 3 of 3]-Minibatch[ 231- 240, 2.93%]: ce = 0.08766073 * 2810; err = 0.32419929 * 2810; time = 0.4633s; samplesPerSecond = 6065.8
dengamma value 1.125270
dengamma value 0.936517
dengamma value 1.035831
dengamma value 1.099219
dengamma value 0.985545
dengamma value 0.986172
dengamma value 0.971048
dengamma value 1.084257
dengamma value 1.028835
dengamma value 0.999442
01/10/2018 19:43:53:  Epoch[ 3 of 3]-Minibatch[ 241- 250, 3.05%]: ce = 0.09091566 * 2540; err = 0.34015748 * 2540; time = 0.3844s; samplesPerSecond = 6607.2
dengamma value 1.044792
dengamma value 1.050796
dengamma value 1.006250
dengamma value 1.016619
dengamma value 1.060446
dengamma value 1.042997
dengamma value 1.042721
dengamma value 1.050817
dengamma value 1.050592
dengamma value 1.013590
01/10/2018 19:43:53:  Epoch[ 3 of 3]-Minibatch[ 251- 260, 3.17%]: ce = 0.09132312 * 2790; err = 0.32508961 * 2790; time = 0.4609s; samplesPerSecond = 6053.3
dengamma value 1.073618
dengamma value 1.062890
dengamma value 1.013564
dengamma value 1.106893
dengamma value 1.039219
dengamma value 1.066712
dengamma value 1.098267
dengamma value 1.084965
dengamma value 1.062020
dengamma value 1.050822
01/10/2018 19:43:54:  Epoch[ 3 of 3]-Minibatch[ 261- 270, 3.30%]: ce = 0.08384624 * 3920; err = 0.26581633 * 3920; time = 0.6741s; samplesPerSecond = 5815.5
dengamma value 1.094288
dengamma value 0.986060
dengamma value 0.983721
dengamma value 1.045874
dengamma value 1.042047
dengamma value 1.048978
dengamma value 1.078403
dengamma value 1.018094
dengamma value 1.021642
dengamma value 1.030332
01/10/2018 19:43:55:  Epoch[ 3 of 3]-Minibatch[ 271- 280, 3.42%]: ce = 0.07674260 * 3370; err = 0.36172107 * 3370; time = 0.4966s; samplesPerSecond = 6786.4
dengamma value 1.017747
dengamma value 1.027135
dengamma value 1.023350
dengamma value 1.045671
dengamma value 1.062357
dengamma value 1.049505
dengamma value 1.005078
dengamma value 1.069661
dengamma value 1.070216
dengamma value 1.069986
01/10/2018 19:43:55:  Epoch[ 3 of 3]-Minibatch[ 281- 290, 3.54%]: ce = 0.09568146 * 2930; err = 0.31979522 * 2930; time = 0.4826s; samplesPerSecond = 6071.2
dengamma value 1.014633
dengamma value 1.019400
dengamma value 1.027631
dengamma value 1.065497
dengamma value 1.108908
dengamma value 1.121512
dengamma value 1.054160
dengamma value 1.012551
dengamma value 1.024221
dengamma value 1.028861
01/10/2018 19:43:56:  Epoch[ 3 of 3]-Minibatch[ 291- 300, 3.66%]: ce = 0.08029908 * 2590; err = 0.31737452 * 2590; time = 0.3995s; samplesPerSecond = 6483.4
dengamma value 1.022766
dengamma value 1.076660
dengamma value 1.023858
dengamma value 1.035982
dengamma value 1.029128
01/10/2018 19:43:56: Finished Epoch[ 3 of 3]: [Training] ce = 0.08510442 * 82070; err = 0.31926404 * 82070; totalSamplesSeen = 246026; learningRatePerSample = 2e-06; epochTime=12.8845s
01/10/2018 19:43:56: SGD: Saving checkpoint model '/tmp/cntk-test-20180110194158.536984/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence'

01/10/2018 19:43:56: Action "train" complete.

01/10/2018 19:43:56: __COMPLETED__